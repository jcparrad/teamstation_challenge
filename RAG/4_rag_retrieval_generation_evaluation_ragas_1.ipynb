{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluation\n",
    "ragas ref:\n",
    "\n",
    "\n",
    "https://docs.ragas.io/en/stable/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juan/Documents/proyectos_propios/jobs/teamstation/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from datasets import Dataset\n",
    "\n",
    "from ragas.integrations.llama_index import evaluate\n",
    "from ragas.metrics import faithfulness, answer_relevancy\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "# Set OpenAI API Key\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize settings\n",
    "Settings.llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-large\")\n",
    "\n",
    "from src_rag import ConfigManager, LoggerManager, Retriever, Reranker, ResponseSynthesizer, RAGQueryEngine, RAGASEvaluator\n",
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.loading:Loading all indices.\n",
      "Loading all indices.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 5, 1, 3, 2, 4, 6, 7, 8, 9, 10, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 27, 28, 11, 12, 13, 23, 26, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Response with Reranker:**\n",
       "Potential consequences of Keytruda include immune-related adverse effects such as colitis, hepatitis, pneumonitis, and the exacerbation of pre-existing autoimmune diseases. It can also lead to symptoms like cough, shortness of breath, chest pain, and changes in vision that should be reported immediately for optimal care and safety."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Response without Reranker:**\n",
       "Potential consequences of Keytruda include immune-related adverse effects such as colitis, hepatitis, pneumonitis, and changes in blood pressure. Additionally, Keytruda can lead to interactions with other medications like steroids and immunosuppressants, affecting its efficacy and safety. Close monitoring for symptoms like cough, chest pain, changes in vision, and neurological symptoms is essential while on Keytruda treatment."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setup configuration and logging\n",
    "config = ConfigManager()\n",
    "api_key = config.load_config()\n",
    "\n",
    "LoggerManager.setup_logging()\n",
    "\n",
    "# Rebuild storage context and load the index\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"./persist\")\n",
    "index = load_index_from_storage(storage_context)\n",
    "\n",
    "# Initialize components\n",
    "retriever = Retriever(index)\n",
    "reranker = Reranker(api_key)\n",
    "synthesizer = ResponseSynthesizer()\n",
    "\n",
    "# Define parameters for both query engines\n",
    "vector_top_k = 30\n",
    "reranker_top_n = 5\n",
    "\n",
    "# Instantiate the query engine with reranking\n",
    "query_engine_with_reranker = RAGQueryEngine(\n",
    "    retriever=retriever,\n",
    "    reranker=reranker,\n",
    "    synthesizer=synthesizer,\n",
    "    vector_top_k=vector_top_k,\n",
    "    reranker_top_n=reranker_top_n,\n",
    "    with_reranker=True\n",
    ")\n",
    "\n",
    "# Instantiate the query engine without reranking\n",
    "query_engine_without_reranker = RAGQueryEngine(\n",
    "    retriever=retriever,\n",
    "    reranker=reranker,  # Reranker is still passed, but reranking won't be used\n",
    "    synthesizer=synthesizer,\n",
    "    vector_top_k=vector_top_k,\n",
    "    reranker_top_n=reranker_top_n,  # This parameter won't be used as reranking is disabled\n",
    "    with_reranker=False\n",
    ")\n",
    "\n",
    "# Define your query\n",
    "query = \"What are potential CONSEQUENCES of Keytruda?\"\n",
    "\n",
    "# Query and display results using the engine with reranking\n",
    "response_with_reranker = query_engine_with_reranker.query(query)\n",
    "response_text_with_reranker = response_with_reranker.response\n",
    "display(Markdown(f\"**Response with Reranker:**\\n{response_text_with_reranker}\"))\n",
    "\n",
    "# Query and display results using the engine without reranking\n",
    "response_without_reranker = query_engine_without_reranker.query(query)\n",
    "response_text_without_reranker = response_without_reranker.response\n",
    "display(Markdown(f\"**Response without Reranker:**\\n{response_text_without_reranker}\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ragas evaluation for RAG  systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metrics = [\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question'],\n",
       "    num_rows: 220\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"../data/processed_data/df_eval.parquet\")\n",
    "ds = df[[\"augmented_questions\"]].rename(columns = {\"augmented_questions\":\"question\"})\n",
    "ds_dict = ds.to_dict()\n",
    "ds_dict[\"question\"] = [v for k, v in ds_dict[\"question\"].items()] \n",
    "\n",
    "ds_dict = ds.to_dict()\n",
    "ds_dict[\"question\"] = [v for k, v in ds_dict[\"question\"].items()] \n",
    "\n",
    "dataset = Dataset.from_dict(ds_dict)\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the evaluator\n",
    "evaluator_llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "evaluator = RAGASEvaluator(evaluator_llm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:   0%|          | 0/220 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 2, 1, 6, 27, 20, 21, 22, 19, 25, 23, 28, 29, 26, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 5, 4, 3, 24]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 14, 17, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 2, 3, 4, 5, 6, 11, 13, 14, 15, 16, 17, 19, 20, 25, 29, 24, 27, 28, 7, 12, 21, 22, 23, 8, 9, 10, 26, 18]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [2, 0, 8, 13, 6, 22, 1, 19, 15, 18, 10, 9, 26, 5, 11, 12, 16, 14, 4, 17, 21, 25, 27, 28, 7, 3, 20, 29, 23, 24]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 4, 2, 5, 6, 8, 17, 25, 29, 14, 12, 11, 10, 9, 16, 21, 23, 27, 26, 18, 19, 24, 20, 22, 13, 7, 3, 1, 15, 28]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [3, 0, 6, 2, 9, 18, 19, 1, 4, 14, 13, 8, 21, 11, 17, 20, 28, 27, 25, 24, 23, 7, 10, 5, 12, 26, 22, 29, 16, 15]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 3, 2, 5, 6, 7, 9, 8, 12, 11, 10, 17, 18, 20, 21, 22, 16, 26, 25, 27, 19, 15, 24, 14, 4, 23, 13, 28, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 17, 19, 16, 9, 22, 8, 13, 20, 21, 25, 23, 28, 29, 14, 18, 4, 5, 7, 10, 12, 27, 2, 3, 6, 11, 15, 26, 24]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 2, 3, 8, 12, 6, 1, 7, 14, 20, 4, 17, 21, 22, 11, 28, 13, 18, 29, 5, 10, 23, 27, 26, 25, 9, 15, 16, 19, 24]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 3, 2, 6, 12, 7, 10, 17, 13, 20, 21, 22, 23, 26, 18, 28, 29, 11, 15, 25, 16, 19, 5, 8, 9, 14, 4, 24, 27]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 2, 4, 7, 8, 13, 21, 29, 5, 11, 19, 25, 26, 1, 9, 15, 17, 18, 23, 24, 3, 6, 14, 27, 10, 12, 16, 20, 22, 28]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:   0%|          | 1/220 [00:02<10:35,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:   1%|▏         | 3/220 [00:03<02:53,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 2, 3, 5, 7, 4, 6, 8, 10, 11, 24, 25, 14, 17, 20, 18, 23, 28, 29, 21, 22, 26, 9, 12, 13, 15, 16, 19, 27]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:   2%|▏         | 5/220 [00:03<01:39,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 25, 26, 27, 28, 29, 23, 24]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:   4%|▎         | 8/220 [00:03<00:50,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:   5%|▍         | 10/220 [00:03<00:38,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:   5%|▌         | 12/220 [00:03<00:32,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 2, 3, 4, 12, 20, 23, 25, 28, 5, 6, 7, 10, 14, 17, 21, 27, 11, 18, 9, 15, 16, 19, 22, 24, 26, 8, 13, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:   6%|▋         | 14/220 [00:04<00:41,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 2, 3, 6, 7, 10, 5, 8, 17, 22, 28, 9, 19, 21, 27, 16, 12, 25, 26, 23, 13, 4, 15, 11, 20, 29, 18, 14, 24]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 5, 21, 14, 29, 6, 18, 8, 27, 10, 24, 22, 13, 19, 7, 4, 9, 26, 15, 23, 17, 20, 11, 3, 28, 2, 25, 12, 16]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 12, 19, 14, 6, 8, 2, 4, 9, 10, 17, 7, 16, 3, 11, 20, 28, 27, 18, 13, 15, 5, 29, 23, 26, 21, 24, 25, 22]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 4, 2, 5, 6, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 24, 25, 26, 27, 21, 22, 28, 29, 3, 7, 8, 9, 10]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 2, 3, 6, 20, 10, 27, 9, 8, 14, 19, 22, 12, 17, 26, 18, 13, 16, 25, 11, 15, 21, 28, 29, 24, 23, 4, 5, 7]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 5, 6, 3, 1, 2, 11, 27, 25, 24, 12, 20, 19, 8, 16, 15, 13, 26, 23, 29, 22, 18, 7, 28, 10, 9, 4, 21, 14, 17]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:   7%|▋         | 16/220 [00:05<01:14,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 18, 15, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 2, 4, 3, 6, 5, 7, 29, 10, 11, 24, 12, 13, 14, 16, 17, 21, 22, 25, 26, 27, 28, 9, 20, 19, 15, 8, 18, 23]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [13, 9, 0, 23, 25, 26, 28, 22, 16, 21, 24, 29, 1, 2, 3, 4, 5, 7, 8, 10, 11, 19, 14, 15, 6, 27, 12, 20, 17, 18]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 2, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [3, 0, 8, 9, 7, 5, 1, 10, 6, 17, 28, 11, 21, 25, 29, 19, 13, 4, 15, 14, 16, 12, 22, 23, 18, 26, 27, 2, 20, 24]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:   8%|▊         | 17/220 [00:06<01:15,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:   8%|▊         | 18/220 [00:06<01:08,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 29, 26, 4, 25, 5, 23, 8, 1, 6, 15, 7, 27, 2, 19, 21, 14, 16, 11, 12, 20, 22, 18, 17, 28, 3, 9, 10, 13, 24]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  10%|█         | 22/220 [00:06<00:35,  5.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 2, 4, 9, 10, 14, 15, 21, 22, 27, 11, 12, 13, 16, 17, 18, 19, 20, 25, 26, 5, 7, 8, 3, 6, 23, 24, 28, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  12%|█▏        | 26/220 [00:06<00:23,  8.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  13%|█▎        | 28/220 [00:07<00:26,  7.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 4, 9, 2, 7, 1, 8, 13, 18, 3, 10, 6, 19, 15, 26, 27, 17, 5, 28, 25, 16, 11, 21, 22, 12, 29, 23, 24, 20, 14]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  14%|█▎        | 30/220 [00:07<00:25,  7.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 29, 27, 5, 4, 3, 8, 24, 20, 9, 12, 26, 11, 13, 14, 6, 19, 16, 25, 10, 18, 7, 2, 21, 15, 17, 22, 23, 28]After Reranking, new rank list for nodes: [0, 2, 1, 3, 5, 6, 4, 8, 9, 7, 13, 10, 12, 11, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 15]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [3, 2, 1, 4, 5, 8, 14, 18, 17, 20, 22, 23, 13, 21, 9, 16, 7, 10, 19, 28, 29, 27, 6, 0, 11, 12, 15, 24, 25, 26]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 2, 3, 4, 5, 6, 7, 17, 23, 29, 26, 22, 21, 27, 18, 24, 12, 19, 16, 14, 13, 9, 10, 15, 20, 25, 28, 11, 8]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 2, 1, 7, 6, 5, 3, 4, 11, 9, 10, 12, 13, 14, 16, 19, 20, 15, 17, 18, 23, 25, 27, 29, 8, 21, 24, 26, 22, 28]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 18, 4, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 23, 2, 4, 5, 6, 7, 9, 10, 13, 14, 15, 16, 18, 19, 20, 21, 22, 24, 25, 28, 1, 3, 8, 11, 12, 17, 26, 27, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 3, 4, 5, 7, 9, 10, 11, 12, 14, 16, 17, 19, 20, 21, 22, 23, 26, 27, 29, 2, 6, 13, 15, 25, 18, 24, 28, 8]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 3, 2, 4, 6, 7, 8, 13, 14, 17, 21, 23, 25, 27, 9, 10, 16, 20, 22, 26, 11, 19, 24, 5, 12, 15, 18, 28, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  15%|█▍        | 32/220 [00:09<01:12,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 4, 8, 3, 7, 10, 5, 6, 11, 16, 17, 20, 23, 26, 14, 15, 25, 9, 21, 24, 1, 13, 2, 29, 19, 18, 12, 22, 27, 28]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  16%|█▋        | 36/220 [00:09<00:44,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 13, 4, 5, 3, 6, 15, 16, 19, 20, 11, 8, 9, 10, 7, 17, 18, 12, 14, 2, 21, 22, 23, 24, 25, 26, 27, 28, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 29, 2, 1, 6, 8, 5, 11, 4, 12, 3, 7, 9, 10, 13, 15, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 14, 16, 24]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  17%|█▋        | 38/220 [00:09<00:37,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  18%|█▊        | 40/220 [00:10<00:35,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [2, 1, 4, 3, 10, 9, 11, 19, 20, 21, 22, 29, 14, 12, 13, 18, 17, 16, 15, 8, 23, 24, 25, 26, 0, 5, 6, 7, 27, 28]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  19%|█▊        | 41/220 [00:10<00:35,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  19%|█▉        | 42/220 [00:10<00:33,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  20%|██        | 44/220 [00:10<00:26,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 2, 3, 5, 8, 10, 11, 12, 13, 14, 15, 20, 21, 22, 23, 27, 4, 7, 17, 18, 25, 26, 28, 29, 6, 16, 19, 24, 9]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  20%|██        | 45/220 [00:11<00:32,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 9, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  21%|██        | 46/220 [00:11<00:52,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 29, 2, 3, 1, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 27, 28, 4, 13, 18, 26]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 3, 2, 1, 4, 5, 7, 10, 11, 12, 21, 19, 20, 22, 24, 27, 6, 9, 16, 25, 26, 28, 29, 17, 18, 23, 8, 13, 14, 15]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [3, 2, 1, 4, 0, 7, 6, 19, 20, 11, 14, 17, 16, 12, 21, 25, 9, 10, 15, 26, 8, 13, 18, 22, 24, 27, 23, 28, 29, 5]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 3, 10, 4, 6, 2, 17, 18, 8, 9, 24, 19, 28, 1, 22, 21, 12, 13, 27, 16, 11, 20, 26, 14, 15, 5, 7, 23, 25, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  21%|██▏       | 47/220 [00:12<01:08,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Reranking, new rank list for nodes: [0, 3, 1, 4, 2, 8, 9, 7, 10, 6, 5, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 25, 26, 27, 28, 29, 21, 23, 24]After Reranking, new rank list for nodes: [0, 4, 11, 3, 9, 6, 17, 22, 29, 14, 25, 13, 7, 5, 12, 10, 18, 1, 8, 2, 19, 20, 21, 23, 24, 26, 27, 28, 15, 16]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 4, 6, 5, 17, 22, 23, 27, 18, 11, 16, 12, 25, 10, 8, 29, 1, 3, 2, 19, 20, 21, 24, 13, 28, 15, 7, 9, 14, 26]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  22%|██▏       | 49/220 [00:12<00:45,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 23, 4, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [3, 2, 1, 4, 0, 18, 17, 20, 19, 15, 12, 11, 16, 10, 6, 8, 21, 27, 25, 26, 22, 23, 13, 7, 28, 29, 9, 5, 14, 24]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 22, 4, 24, 1, 19, 16, 17, 28, 23, 21, 14, 15, 27, 25, 26, 20, 18, 29, 2, 3, 5, 9, 10, 6, 7, 8, 11, 12, 13]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 11, 3, 9, 4, 19, 13, 6, 14, 20, 8, 18, 7, 16, 27, 23, 24, 29, 26, 28, 25, 5, 10, 12, 15, 2, 17, 21, 22]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  23%|██▎       | 51/220 [00:13<00:49,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 2, 3, 4, 7, 13, 16, 17, 18, 23, 26, 27, 1, 5, 6, 10, 11, 12, 21, 24, 8, 25, 22, 9, 14, 15, 19, 20, 28, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 7, 4, 6, 10, 8, 14, 20, 23, 21, 24, 29, 16, 13, 3, 9, 2, 17, 18, 12, 11, 19, 5, 22, 15, 25, 26, 27, 28]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 4, 7, 10, 11, 14, 17, 18, 20, 22, 23, 24, 28, 9, 13, 21, 16, 25, 26, 27, 2, 3, 8, 12, 5, 6, 15, 19, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  25%|██▍       | 54/220 [00:13<00:36,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  26%|██▌       | 57/220 [00:13<00:24,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  27%|██▋       | 59/220 [00:14<00:22,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  28%|██▊       | 61/220 [00:14<00:23,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.858000 seconds\n",
      "Retrying request to /chat/completions in 0.858000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.788000 seconds\n",
      "Retrying request to /chat/completions in 0.788000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 2, 1, 4, 5, 6, 9, 13, 15, 16, 21, 18, 19, 20, 11, 12, 14, 3, 7, 10, 17, 25, 23, 24, 28, 29, 8, 22, 26, 27]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.535000 seconds\n",
      "Retrying request to /chat/completions in 0.535000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 2, 6, 12, 26, 3, 4, 5, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.342000 seconds\n",
      "Retrying request to /chat/completions in 0.342000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 3, 5, 2, 9, 1, 4, 7, 13, 15, 16, 21, 11, 12, 14, 23, 24, 26, 27, 8, 18, 25, 6, 28, 29, 22, 17, 19, 20, 10]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 4, 5, 6, 3, 1, 7, 9, 11, 12, 17, 18, 16, 20, 29, 23, 24, 21, 19, 13, 27, 28, 22, 25, 26, 2, 8, 10, 14, 15]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.118000 seconds\n",
      "Retrying request to /chat/completions in 0.118000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.156000 seconds\n",
      "Retrying request to /chat/completions in 0.156000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.067000 seconds\n",
      "Retrying request to /chat/completions in 0.067000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.103000 seconds\n",
      "Retrying request to /chat/completions in 0.103000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.060000 seconds\n",
      "Retrying request to /chat/completions in 0.060000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.068000 seconds\n",
      "Retrying request to /chat/completions in 0.068000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 8, 21, 6, 4, 16, 17, 13, 12, 20, 18, 22, 24, 29, 28, 26, 23, 19, 15, 14, 11, 10, 9, 7, 5, 3, 2, 27, 25]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 4, 2, 3, 5, 18, 22, 24, 14, 28, 13, 20, 21, 26, 19, 17, 11, 12, 8, 9, 6, 1, 7, 23, 16, 25, 29, 10, 15, 27]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.885000 seconds\n",
      "Retrying request to /chat/completions in 0.885000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.170000 seconds\n",
      "Retrying request to /chat/completions in 0.170000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.878000 seconds\n",
      "After Reranking, new rank list for nodes: [0, 1, 7, 10, 23, 9, 20, 22, 11, 2, 6, 17, 14, 28, 13, 3, 4, 5, 8, 18, 12, 29, 27, 16, 21, 24, 26, 19, 15, 25]Retrying request to /chat/completions in 0.878000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.896000 seconds\n",
      "Retrying request to /chat/completions in 0.896000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  28%|██▊       | 62/220 [00:15<00:57,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [3, 2, 1, 4, 0, 7, 6, 14, 16, 17, 18, 19, 20, 22, 26, 27, 21, 24, 23, 9, 10, 11, 12, 13, 8, 25, 28, 29, 5, 15]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.587000 seconds\n",
      "Retrying request to /chat/completions in 0.587000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.114000 seconds\n",
      "Retrying request to /chat/completions in 0.114000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.050000 seconds\n",
      "Retrying request to /chat/completions in 0.050000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 16, 15, 28]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.036000 seconds\n",
      "Retrying request to /chat/completions in 0.036000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  29%|██▊       | 63/220 [00:16<01:01,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  29%|██▉       | 64/220 [00:16<00:52,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Reranking, new rank list for nodes: [0, 5, 6, 11, 4, 2, 3, 12, 13, 14, 17, 18, 20, 23, 29, 9, 8, 7, 24, 28, 16, 21, 25, 27, 1, 19, 15, 26, 10, 22]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 5, 15, 1, 7, 9, 11, 12, 21, 22, 14, 16, 20, 24, 28, 2, 6, 8, 10, 13, 18, 19, 23, 26, 27, 3, 4, 25, 17, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7685619468684706 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199544, Requested 3211. Please try again in 826ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7685619468684706 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199544, Requested 3211. Please try again in 826ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.024000 seconds\n",
      "Retrying request to /chat/completions in 0.024000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.729000 seconds\n",
      "Retrying request to /chat/completions in 0.729000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  30%|███       | 66/220 [00:16<00:38,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.5244684703657554 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199599, Requested 3132. Please try again in 819ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.5244684703657554 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199599, Requested 3132. Please try again in 819ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.08713855030325868 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199589, Requested 3199. Please try again in 836ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.08713855030325868 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199589, Requested 3199. Please try again in 836ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.013043855554961015 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199554, Requested 3179. Please try again in 819ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.013043855554961015 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199554, Requested 3179. Please try again in 819ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  30%|███       | 67/220 [00:16<00:33,  4.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.790000 seconds\n",
      "Retrying request to /chat/completions in 0.790000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.747000 seconds\n",
      "Retrying request to /chat/completions in 0.747000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.752000 seconds\n",
      "Retrying request to /chat/completions in 0.752000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  31%|███▏      | 69/220 [00:17<00:27,  5.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.597000 seconds\n",
      "Retrying request to /chat/completions in 0.597000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  32%|███▏      | 70/220 [00:17<00:27,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 4, 3, 2, 5, 29, 19, 18, 7, 6, 8, 24, 26, 21, 22, 16, 12, 13, 9, 10, 11, 23, 17, 28, 15, 20, 25, 27, 14]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.242000 seconds\n",
      "Retrying request to /chat/completions in 0.242000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  32%|███▏      | 71/220 [00:17<00:27,  5.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.122000 seconds\n",
      "Retrying request to /chat/completions in 0.122000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.035000 seconds\n",
      "Retrying request to /chat/completions in 0.035000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.072000 seconds\n",
      "Retrying request to /chat/completions in 0.072000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.160000 seconds\n",
      "Retrying request to /chat/completions in 0.160000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.783000 seconds\n",
      "Retrying request to /chat/completions in 0.783000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.759000 seconds\n",
      "Retrying request to /chat/completions in 0.759000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.762000 seconds\n",
      "Retrying request to /chat/completions in 0.762000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.718000 seconds\n",
      "Retrying request to /chat/completions in 0.718000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.722000 seconds\n",
      "Retrying request to /chat/completions in 0.722000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.723000 seconds\n",
      "Retrying request to /chat/completions in 0.723000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.625000 seconds\n",
      "Retrying request to /chat/completions in 0.625000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.790000 seconds\n",
      "Retrying request to /chat/completions in 0.790000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.795000 seconds\n",
      "Retrying request to /chat/completions in 0.795000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.789000 seconds\n",
      "Retrying request to /chat/completions in 0.789000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.678000 seconds\n",
      "Retrying request to /chat/completions in 0.678000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.688000 seconds\n",
      "Retrying request to /chat/completions in 0.688000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  33%|███▎      | 73/220 [00:18<00:46,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.044000 seconds\n",
      "Retrying request to /chat/completions in 0.044000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.8588974681871582 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197085, Requested 3039. Please try again in 37ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.8588974681871582 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197085, Requested 3039. Please try again in 37ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.025000 seconds\n",
      "Retrying request to /chat/completions in 0.025000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.030000 seconds\n",
      "Retrying request to /chat/completions in 0.030000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.018000 seconds\n",
      "Retrying request to /chat/completions in 0.018000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.044000 seconds\n",
      "Retrying request to /chat/completions in 0.044000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.029000 seconds\n",
      "Retrying request to /chat/completions in 0.029000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.840000 seconds\n",
      "Retrying request to /chat/completions in 0.840000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.023513943038343088 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199735, Requested 3035. Please try again in 831ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.023513943038343088 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199735, Requested 3035. Please try again in 831ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.9643622921474713 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199697, Requested 3132. Please try again in 848ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.9643622921474713 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199697, Requested 3132. Please try again in 848ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 1.5033812873084333 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199602, Requested 3211. Please try again in 843ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 1.5033812873084333 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199602, Requested 3211. Please try again in 843ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.821000 seconds\n",
      "Retrying request to /chat/completions in 0.821000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.814000 seconds\n",
      "Retrying request to /chat/completions in 0.814000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7071463918667034 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199556, Requested 3193. Please try again in 824ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7071463918667034 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199556, Requested 3193. Please try again in 824ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.813000 seconds\n",
      "Retrying request to /chat/completions in 0.813000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.834000 seconds\n",
      "Retrying request to /chat/completions in 0.834000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.809000 seconds\n",
      "Retrying request to /chat/completions in 0.809000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.805000 seconds\n",
      "Retrying request to /chat/completions in 0.805000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.672000 seconds\n",
      "Retrying request to /chat/completions in 0.672000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 3, 5, 4, 2, 6, 19, 15, 10, 11, 16, 18, 27, 23, 22, 25, 28, 24, 29, 26, 17, 20, 21, 7, 8, 9, 13, 12, 14]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.477000 seconds\n",
      "Retrying request to /chat/completions in 0.477000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.854000 seconds\n",
      "Retrying request to /chat/completions in 0.854000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.752000 seconds\n",
      "Retrying request to /chat/completions in 0.752000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.4556268351888866 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199438, Requested 3031. Please try again in 740ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.4556268351888866 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199438, Requested 3031. Please try again in 740ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.785000 seconds\n",
      "Retrying request to /chat/completions in 0.785000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.748000 seconds\n",
      "Retrying request to /chat/completions in 0.748000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.2411057791872233 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199342, Requested 3108. Please try again in 735ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.2411057791872233 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199342, Requested 3108. Please try again in 735ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 1.6211267918935999 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199317, Requested 3179. Please try again in 748ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 1.6211267918935999 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199317, Requested 3179. Please try again in 748ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.15419634286733208 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199300, Requested 3199. Please try again in 749ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.15419634286733208 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199300, Requested 3199. Please try again in 749ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.741000 seconds\n",
      "Retrying request to /chat/completions in 0.741000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.4168867760145235 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199242, Requested 3255. Please try again in 749ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.4168867760145235 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199242, Requested 3255. Please try again in 749ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.576000 seconds\n",
      "Retrying request to /chat/completions in 0.576000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.436000 seconds\n",
      "Retrying request to /chat/completions in 0.436000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.351000 seconds\n",
      "Retrying request to /chat/completions in 0.351000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.134000 seconds\n",
      "Retrying request to /chat/completions in 0.134000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.169000 seconds\n",
      "Retrying request to /chat/completions in 0.169000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.049000 seconds\n",
      "Retrying request to /chat/completions in 0.049000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.775000 seconds\n",
      "Retrying request to /chat/completions in 0.775000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.793000 seconds\n",
      "Retrying request to /chat/completions in 0.793000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.8188695743426939 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199500, Requested 3133. Please try again in 789ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.8188695743426939 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199500, Requested 3133. Please try again in 789ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.08309059327679813 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199457, Requested 3186. Please try again in 792ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.08309059327679813 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199457, Requested 3186. Please try again in 792ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.797000 seconds\n",
      "Retrying request to /chat/completions in 0.797000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.786000 seconds\n",
      "Retrying request to /chat/completions in 0.786000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.765000 seconds\n",
      "Retrying request to /chat/completions in 0.765000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.796000 seconds\n",
      "Retrying request to /chat/completions in 0.796000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.775000 seconds\n",
      "Retrying request to /chat/completions in 0.775000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.747000 seconds\n",
      "Retrying request to /chat/completions in 0.747000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 2, 4, 5, 3, 1, 6, 7, 8, 10, 11, 9, 13, 16, 18, 21, 22, 27, 24, 26, 29, 23, 28, 20, 19, 17, 12, 15, 25, 14]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.521000 seconds\n",
      "Retrying request to /chat/completions in 0.521000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 6, 23, 10, 5, 27, 16, 29, 17, 24, 18, 7, 15, 8, 9, 21, 20, 13, 12, 14, 11, 22, 19, 4, 3, 2, 28, 25, 26]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.014000 seconds\n",
      "Retrying request to /chat/completions in 0.014000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.893000 seconds\n",
      "Retrying request to /chat/completions in 0.893000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.878000 seconds\n",
      "Retrying request to /chat/completions in 0.878000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.864000 seconds\n",
      "Retrying request to /chat/completions in 0.864000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.879000 seconds\n",
      "Retrying request to /chat/completions in 0.879000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.878000 seconds\n",
      "Retrying request to /chat/completions in 0.878000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.17228744261456896 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199686, Requested 3200. Please try again in 865ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.17228744261456896 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199686, Requested 3200. Please try again in 865ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.129000 seconds\n",
      "Retrying request to /chat/completions in 0.129000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.844000 seconds\n",
      "Retrying request to /chat/completions in 0.844000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.860000 seconds\n",
      "Retrying request to /chat/completions in 0.860000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.809000 seconds\n",
      "Retrying request to /chat/completions in 0.809000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.800000 seconds\n",
      "Retrying request to /chat/completions in 0.800000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  34%|███▎      | 74/220 [00:21<02:19,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.722000 seconds\n",
      "Retrying request to /chat/completions in 0.722000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.650000 seconds\n",
      "Retrying request to /chat/completions in 0.650000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  34%|███▍      | 75/220 [00:22<02:10,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.031000 seconds\n",
      "Retrying request to /chat/completions in 0.031000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.4932861422346848 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196961, Requested 3108. Please try again in 20ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.4932861422346848 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196961, Requested 3108. Please try again in 20ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[50]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196942, Requested 3132. Please try again in 22ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[50]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196942, Requested 3132. Please try again in 22ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  35%|███▍      | 76/220 [00:22<01:40,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 1.4476321778135708 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196930, Requested 3193. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 1.4476321778135708 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196930, Requested 3193. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.9049093275853992 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196919, Requested 3186. Please try again in 31ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.034000 seconds\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.9049093275853992 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196919, Requested 3186. Please try again in 31ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying request to /chat/completions in 0.034000 seconds\n",
      "ERROR:ragas.executor:Exception raised in Job[152]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196896, Requested 3199. Please try again in 28ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[152]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196896, Requested 3199. Please try again in 28ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 1.9637916962559754 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196853, Requested 3255. Please try again in 32ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 1.9637916962559754 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196853, Requested 3255. Please try again in 32ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "ERROR:ragas.executor:Exception raised in Job[186]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196854, Requested 3211. Please try again in 19ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[186]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196854, Requested 3211. Please try again in 19ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 4, 5, 6, 7, 8, 9, 12, 13, 17, 18, 19, 24, 28, 2, 3, 10, 11, 14, 15, 16, 20, 21, 22, 23, 25, 26, 27, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.905000 seconds\n",
      "Retrying request to /chat/completions in 0.905000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.882000 seconds\n",
      "Retrying request to /chat/completions in 0.882000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.876000 seconds\n",
      "Retrying request to /chat/completions in 0.876000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  36%|███▌      | 79/220 [00:22<00:56,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.705000 seconds\n",
      "Retrying request to /chat/completions in 0.705000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 15, 7, 27, 17, 6, 28, 19, 1, 11, 5, 10, 14, 20, 21, 13, 9, 3, 2, 23, 8, 22, 18, 4, 25, 24, 16, 12, 29, 26]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.631000 seconds\n",
      "Retrying request to /chat/completions in 0.631000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.607000 seconds\n",
      "Retrying request to /chat/completions in 0.607000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.589000 seconds\n",
      "Retrying request to /chat/completions in 0.589000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.545000 seconds\n",
      "Retrying request to /chat/completions in 0.545000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.219000 seconds\n",
      "Retrying request to /chat/completions in 0.219000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.119000 seconds\n",
      "Retrying request to /chat/completions in 0.119000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  36%|███▋      | 80/220 [00:23<01:05,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.930000 seconds\n",
      "Retrying request to /chat/completions in 0.930000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 1.1378150966078504 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199953, Requested 3133. Please try again in 925ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 1.1378150966078504 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199953, Requested 3133. Please try again in 925ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.066000 seconds\n",
      "Retrying request to /chat/completions in 0.066000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.803000 seconds\n",
      "Retrying request to /chat/completions in 0.803000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.802000 seconds\n",
      "Retrying request to /chat/completions in 0.802000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.803000 seconds\n",
      "Retrying request to /chat/completions in 0.803000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.807000 seconds\n",
      "Retrying request to /chat/completions in 0.807000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.807000 seconds\n",
      "Retrying request to /chat/completions in 0.807000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.772000 seconds\n",
      "Retrying request to /chat/completions in 0.772000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.819000 seconds\n",
      "Retrying request to /chat/completions in 0.819000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.657000 seconds\n",
      "Retrying request to /chat/completions in 0.657000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 4, 2, 6, 7, 8, 1, 19, 28, 11, 14, 21, 29, 18, 15, 23, 24, 20, 26, 5, 16, 10, 9, 25, 22, 17, 3, 12, 13, 27]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  37%|███▋      | 81/220 [00:24<01:13,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.139000 seconds\n",
      "Retrying request to /chat/completions in 0.139000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.083000 seconds\n",
      "Retrying request to /chat/completions in 0.083000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.880000 seconds\n",
      "Retrying request to /chat/completions in 0.880000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.888000 seconds\n",
      "Retrying request to /chat/completions in 0.888000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.886000 seconds\n",
      "Retrying request to /chat/completions in 0.886000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.9087140489130368 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199753, Requested 3200. Please try again in 885ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.9087140489130368 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199753, Requested 3200. Please try again in 885ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.847000 seconds\n",
      "Retrying request to /chat/completions in 0.847000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.871000 seconds\n",
      "Retrying request to /chat/completions in 0.871000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.784000 seconds\n",
      "Retrying request to /chat/completions in 0.784000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.855000 seconds\n",
      "Retrying request to /chat/completions in 0.855000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.031000 seconds\n",
      "Retrying request to /chat/completions in 0.031000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.799000 seconds\n",
      "Retrying request to /chat/completions in 0.799000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.669000 seconds\n",
      "Retrying request to /chat/completions in 0.669000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.813000 seconds\n",
      "Retrying request to /chat/completions in 0.813000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  37%|███▋      | 82/220 [00:25<01:36,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 2, 5, 1, 3, 4, 26, 6, 27, 9, 21, 10, 16, 17, 12, 8, 20, 28, 11, 29, 7, 25, 18, 23, 13, 14, 15, 22, 19, 24]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[51]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199793, Requested 3108. Please try again in 870ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[51]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199793, Requested 3108. Please try again in 870ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[187]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199730, Requested 3186. Please try again in 874ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[187]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199730, Requested 3186. Please try again in 874ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.1329942514525858 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199720, Requested 3142. Please try again in 858ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.1329942514525858 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199720, Requested 3142. Please try again in 858ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.9490892632676026 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199690, Requested 3186. Please try again in 862ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.9490892632676026 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199690, Requested 3186. Please try again in 862ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.8838188294269033 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199684, Requested 3212. Please try again in 868ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.8838188294269033 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199684, Requested 3212. Please try again in 868ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.9325108472631143 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199640, Requested 3190. Please try again in 849ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.9325108472631143 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199640, Requested 3190. Please try again in 849ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.848000 seconds\n",
      "Retrying request to /chat/completions in 0.848000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.886000 seconds\n",
      "Retrying request to /chat/completions in 0.886000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.809000 seconds\n",
      "Retrying request to /chat/completions in 0.809000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.722000 seconds\n",
      "Retrying request to /chat/completions in 0.722000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.002000 seconds\n",
      "Retrying request to /chat/completions in 0.002000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.681000 seconds\n",
      "Retrying request to /chat/completions in 0.681000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.788000 seconds\n",
      "Retrying request to /chat/completions in 0.788000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 14, 12, 9, 5, 29, 4, 3, 1, 21, 27, 26, 25, 22, 19, 17, 16, 15, 13, 10, 8, 6, 2, 20, 11, 7, 28, 24, 23, 18]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.366000 seconds\n",
      "Retrying request to /chat/completions in 0.366000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.243000 seconds\n",
      "Retrying request to /chat/completions in 0.243000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.367000 seconds\n",
      "Retrying request to /chat/completions in 0.367000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  39%|███▊      | 85/220 [00:26<01:09,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.011000 seconds\n",
      "Retrying request to /chat/completions in 0.011000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.944000 seconds\n",
      "Retrying request to /chat/completions in 0.944000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[153]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199938, Requested 3193. Please try again in 939ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[153]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199938, Requested 3193. Please try again in 939ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.906000 seconds\n",
      "Retrying request to /chat/completions in 0.906000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[120]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199776, Requested 3255. Please try again in 909ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[120]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199776, Requested 3255. Please try again in 909ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  40%|███▉      | 87/220 [00:26<00:48,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.051000 seconds\n",
      "Retrying request to /chat/completions in 0.051000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.842000 seconds\n",
      "Retrying request to /chat/completions in 0.842000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.779000 seconds\n",
      "Retrying request to /chat/completions in 0.779000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.813000 seconds\n",
      "Retrying request to /chat/completions in 0.813000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.796000 seconds\n",
      "Retrying request to /chat/completions in 0.796000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.800000 seconds\n",
      "Retrying request to /chat/completions in 0.800000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.808000 seconds\n",
      "Retrying request to /chat/completions in 0.808000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.744000 seconds\n",
      "Retrying request to /chat/completions in 0.744000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.740000 seconds\n",
      "Retrying request to /chat/completions in 0.740000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  40%|████      | 88/220 [00:27<00:56,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.092000 seconds\n",
      "Retrying request to /chat/completions in 0.092000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.8957643552399742 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196973, Requested 3045. Please try again in 5ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.8957643552399742 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196973, Requested 3045. Please try again in 5ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.026000 seconds\n",
      "Retrying request to /chat/completions in 0.026000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.030000 seconds\n",
      "Retrying request to /chat/completions in 0.030000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.031000 seconds\n",
      "Retrying request to /chat/completions in 0.031000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.032000 seconds\n",
      "Retrying request to /chat/completions in 0.032000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.028000 seconds\n",
      "Retrying request to /chat/completions in 0.028000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.931000 seconds\n",
      "Retrying request to /chat/completions in 0.931000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.922000 seconds\n",
      "Retrying request to /chat/completions in 0.922000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.896000 seconds\n",
      "Retrying request to /chat/completions in 0.896000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.807000 seconds\n",
      "Retrying request to /chat/completions in 0.807000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.23886159485279035 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199440, Requested 3142. Please try again in 774ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.23886159485279035 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199440, Requested 3142. Please try again in 774ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.772000 seconds\n",
      "Retrying request to /chat/completions in 0.772000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.9646979509201103 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199361, Requested 3209. Please try again in 771ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.9646979509201103 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199361, Requested 3209. Please try again in 771ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[154]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199364, Requested 3200. Please try again in 769ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[154]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199364, Requested 3200. Please try again in 769ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.769000 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  40%|████      | 89/220 [00:27<00:57,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying request to /chat/completions in 0.769000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.695000 seconds\n",
      "Retrying request to /chat/completions in 0.695000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.593000 seconds\n",
      "Retrying request to /chat/completions in 0.593000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.370000 seconds\n",
      "Retrying request to /chat/completions in 0.370000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 1.521401 seconds\n",
      "Retrying request to /chat/completions in 1.521401 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.015000 seconds\n",
      "Retrying request to /chat/completions in 0.015000 seconds\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.6464615016472548 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197002, Requested 3186. Please try again in 56ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.6464615016472548 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197002, Requested 3186. Please try again in 56ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.041000 seconds\n",
      "Retrying request to /chat/completions in 0.041000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.8657450378289623 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196963, Requested 3136. Please try again in 29ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.8657450378289623 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196963, Requested 3136. Please try again in 29ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.948000 seconds\n",
      "Retrying request to /chat/completions in 0.948000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.949000 seconds\n",
      "Retrying request to /chat/completions in 0.949000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.5482453428020226 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196942, Requested 3212. Please try again in 46ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.5482453428020226 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196942, Requested 3212. Please try again in 46ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.900000 seconds\n",
      "Retrying request to /chat/completions in 0.900000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 9, 12, 6, 8, 1, 7, 10, 11, 17, 18, 21, 22, 28, 5, 26, 15, 19, 25, 24, 23, 27, 16, 14, 20, 2, 3, 4, 13, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.793000 seconds\n",
      "Retrying request to /chat/completions in 0.793000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.799000 seconds\n",
      "Retrying request to /chat/completions in 0.799000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.740000 seconds\n",
      "Retrying request to /chat/completions in 0.740000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  41%|████      | 90/220 [00:29<01:23,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.553000 seconds\n",
      "Retrying request to /chat/completions in 0.553000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.342000 seconds\n",
      "Retrying request to /chat/completions in 0.342000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.339000 seconds\n",
      "Retrying request to /chat/completions in 0.339000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 29, 15, 9, 10, 19, 26, 20, 21, 25, 28, 14, 24, 11, 2, 4, 7, 8, 17, 3, 23, 6, 12, 16, 13, 18, 22, 1, 5, 27]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.036000 seconds\n",
      "Retrying request to /chat/completions in 0.036000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.002000 seconds\n",
      "Retrying request to /chat/completions in 0.002000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  41%|████▏     | 91/220 [00:29<01:21,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.915000 seconds\n",
      "Retrying request to /chat/completions in 0.915000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.872000 seconds\n",
      "Retrying request to /chat/completions in 0.872000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.6662816673716747 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199683, Requested 3192. Please try again in 862ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.6662816673716747 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199683, Requested 3192. Please try again in 862ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 1.144918014815696 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199727, Requested 3190. Please try again in 875ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 1.144918014815696 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199727, Requested 3190. Please try again in 875ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.9361250545700086 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199608, Requested 3045. Please try again in 795ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.9361250545700086 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199608, Requested 3045. Please try again in 795ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.798000 seconds\n",
      "Retrying request to /chat/completions in 0.798000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.805000 seconds\n",
      "Retrying request to /chat/completions in 0.805000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.753000 seconds\n",
      "Retrying request to /chat/completions in 0.753000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.751000 seconds\n",
      "Retrying request to /chat/completions in 0.751000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.742000 seconds\n",
      "Retrying request to /chat/completions in 0.742000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 2, 3, 7, 6, 8, 17, 16, 12, 20, 19, 23, 26, 28, 9, 22, 21, 13, 11, 10, 1, 4, 5, 14, 25, 27, 24, 15, 18, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.662655567338041 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 198517, Requested 2935. Please try again in 435ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.662655567338041 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 198517, Requested 2935. Please try again in 435ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  42%|████▏     | 92/220 [00:30<01:28,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.141000 seconds\n",
      "Retrying request to /chat/completions in 0.141000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.270000 seconds\n",
      "Retrying request to /chat/completions in 0.270000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.201000 seconds\n",
      "Retrying request to /chat/completions in 0.201000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.201000 seconds\n",
      "Retrying request to /chat/completions in 0.201000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.196000 seconds\n",
      "Retrying request to /chat/completions in 0.196000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.194000 seconds\n",
      "Retrying request to /chat/completions in 0.194000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.188000 seconds\n",
      "Retrying request to /chat/completions in 0.188000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.193000 seconds\n",
      "Retrying request to /chat/completions in 0.193000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[53]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197507, Requested 3142. Please try again in 194ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[53]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197507, Requested 3142. Please try again in 194ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  42%|████▏     | 93/220 [00:31<01:14,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.033000 seconds\n",
      "Retrying request to /chat/completions in 0.033000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.070000 seconds\n",
      "Retrying request to /chat/completions in 0.070000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.749000 seconds\n",
      "Retrying request to /chat/completions in 0.749000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7632487248027751 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199448, Requested 3136. Please try again in 775ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7632487248027751 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199448, Requested 3136. Please try again in 775ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.710000 seconds\n",
      "Retrying request to /chat/completions in 0.710000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[155]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199463, Requested 3186. Please try again in 794ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[155]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199463, Requested 3186. Please try again in 794ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  43%|████▎     | 94/220 [00:31<01:01,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[121]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199417, Requested 3212. Please try again in 788ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[121]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199417, Requested 3212. Please try again in 788ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.24940311235163726 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199397, Requested 3184. Please try again in 774ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.24940311235163726 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199397, Requested 3184. Please try again in 774ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.777000 seconds\n",
      "Retrying request to /chat/completions in 0.777000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.777000 seconds\n",
      "Retrying request to /chat/completions in 0.777000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.764000 seconds\n",
      "Retrying request to /chat/completions in 0.764000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.745000 seconds\n",
      "Retrying request to /chat/completions in 0.745000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.680029438472755 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199331, Requested 3209. Please try again in 762ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.680029438472755 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199331, Requested 3209. Please try again in 762ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 2, 1, 29, 11, 25, 16, 20, 21, 6, 7, 8, 9, 12, 10, 4, 19, 15, 14, 13, 3, 23, 24, 18, 5, 17, 26, 27, 28, 22]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.287000 seconds\n",
      "Retrying request to /chat/completions in 0.287000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.351000 seconds\n",
      "Retrying request to /chat/completions in 0.351000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.134000 seconds\n",
      "Retrying request to /chat/completions in 0.134000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.126000 seconds\n",
      "Retrying request to /chat/completions in 0.126000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.088000 seconds\n",
      "Retrying request to /chat/completions in 0.088000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.862000 seconds\n",
      "Retrying request to /chat/completions in 0.862000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.932000 seconds\n",
      "Retrying request to /chat/completions in 0.932000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.883000 seconds\n",
      "Retrying request to /chat/completions in 0.883000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.875000 seconds\n",
      "Retrying request to /chat/completions in 0.875000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 1.5044262460542064 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199760, Requested 3192. Please try again in 885ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 1.5044262460542064 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199760, Requested 3192. Please try again in 885ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.6070490555153449 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199751, Requested 3203. Please try again in 886ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.6070490555153449 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199751, Requested 3203. Please try again in 886ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.870000 seconds\n",
      "Retrying request to /chat/completions in 0.870000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  44%|████▍     | 97/220 [00:32<00:48,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.723000 seconds\n",
      "Retrying request to /chat/completions in 0.723000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.726000 seconds\n",
      "Retrying request to /chat/completions in 0.726000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.720000 seconds\n",
      "Retrying request to /chat/completions in 0.720000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.724000 seconds\n",
      "Retrying request to /chat/completions in 0.724000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.608000 seconds\n",
      "Retrying request to /chat/completions in 0.608000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 2, 5, 7, 17, 14, 24, 28, 4, 9, 11, 12, 13, 18, 20, 19, 25, 26, 27, 21, 6, 10, 15, 16, 8, 3, 22, 29, 23]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.025000 seconds\n",
      "Retrying request to /chat/completions in 0.025000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.832000 seconds\n",
      "Retrying request to /chat/completions in 0.832000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.747000 seconds\n",
      "Retrying request to /chat/completions in 0.747000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.771000 seconds\n",
      "Retrying request to /chat/completions in 0.771000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.783000 seconds\n",
      "Retrying request to /chat/completions in 0.783000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.773000 seconds\n",
      "Retrying request to /chat/completions in 0.773000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.771000 seconds\n",
      "Retrying request to /chat/completions in 0.771000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.753000 seconds\n",
      "Retrying request to /chat/completions in 0.753000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.6054714808150269 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199346, Requested 3140. Please try again in 745ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.1947052315529143 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199403, Requested 3184. Please try again in 776ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.6054714808150269 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199346, Requested 3140. Please try again in 745ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.1947052315529143 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199403, Requested 3184. Please try again in 776ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.756000 seconds\n",
      "Retrying request to /chat/completions in 0.756000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.747000 seconds\n",
      "Retrying request to /chat/completions in 0.747000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.405000 seconds\n",
      "Retrying request to /chat/completions in 0.405000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 3, 1, 2, 6, 24, 21, 10, 8, 28, 9, 29, 23, 25, 26, 27, 20, 4, 5, 7, 12, 19, 16, 17, 11, 18, 15, 22, 13, 14]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.052000 seconds\n",
      "Retrying request to /chat/completions in 0.052000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.5288539113991778 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199655, Requested 2961. Please try again in 784ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.5288539113991778 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199655, Requested 2961. Please try again in 784ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.823000 seconds\n",
      "Retrying request to /chat/completions in 0.823000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.9650333005139313 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199510, Requested 3110. Please try again in 786ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.9650333005139313 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199510, Requested 3110. Please try again in 786ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.6606972505414133 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199452, Requested 3179. Please try again in 789ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.6606972505414133 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199452, Requested 3179. Please try again in 789ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.789000 seconds\n",
      "Retrying request to /chat/completions in 0.789000 seconds\n",
      "ERROR:ragas.executor:Exception raised in Job[189]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199430, Requested 3190. Please try again in 786ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[189]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199430, Requested 3190. Please try again in 786ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  45%|████▍     | 98/220 [00:34<01:23,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.768000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "Retrying request to /chat/completions in 0.768000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.779000 seconds\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "Retrying request to /chat/completions in 0.779000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.783000 seconds\n",
      "Retrying request to /chat/completions in 0.783000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.8613676529928759 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199380, Requested 3213. Please try again in 777ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.8613676529928759 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199380, Requested 3213. Please try again in 777ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.776000 seconds\n",
      "Retrying request to /chat/completions in 0.776000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.038000 seconds\n",
      "Retrying request to /chat/completions in 0.038000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  45%|████▌     | 99/220 [00:34<01:16,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.393000 seconds\n",
      "Retrying request to /chat/completions in 0.393000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.367000 seconds\n",
      "Retrying request to /chat/completions in 0.367000 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  45%|████▌     | 100/220 [00:34<01:03,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.281000 seconds\n",
      "Retrying request to /chat/completions in 0.281000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[54]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197423, Requested 3136. Please try again in 167ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[54]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197423, Requested 3136. Please try again in 167ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.24459346556193828 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197362, Requested 3178. Please try again in 162ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.24459346556193828 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197362, Requested 3178. Please try again in 162ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.168000 seconds\n",
      "Retrying request to /chat/completions in 0.168000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.157000 seconds\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.4744289767891745 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197351, Requested 3203. Please try again in 166ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying request to /chat/completions in 0.157000 seconds\n",
      "ERROR:ragas.executor:Exception raised in Job[122]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197350, Requested 3209. Please try again in 167ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.4744289767891745 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197351, Requested 3203. Please try again in 166ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Exception raised in Job[122]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197350, Requested 3209. Please try again in 167ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  46%|████▌     | 101/220 [00:34<00:54,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.049000 seconds\n",
      "Retrying request to /chat/completions in 0.049000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 3, 5, 15, 29, 2, 4, 6, 7, 9, 10, 12, 16, 19, 20, 21, 23, 14, 24, 25, 26, 27, 28, 11, 13, 17, 18, 22, 8]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.743000 seconds\n",
      "Retrying request to /chat/completions in 0.743000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.726000 seconds\n",
      "Retrying request to /chat/completions in 0.726000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.761000 seconds\n",
      "Retrying request to /chat/completions in 0.761000 seconds\n",
      "ERROR:ragas.executor:Exception raised in Job[123]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199295, Requested 3184. Please try again in 743ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[123]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199295, Requested 3184. Please try again in 743ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  47%|████▋     | 103/220 [00:35<00:37,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.747000 seconds\n",
      "Retrying request to /chat/completions in 0.747000 seconds\n",
      "ERROR:ragas.executor:Exception raised in Job[190]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199302, Requested 3192. Please try again in 748ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[190]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199302, Requested 3192. Please try again in 748ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.631000 seconds\n",
      "Retrying request to /chat/completions in 0.631000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.748000 seconds\n",
      "Retrying request to /chat/completions in 0.748000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.617000 seconds\n",
      "Retrying request to /chat/completions in 0.617000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.603000 seconds\n",
      "Retrying request to /chat/completions in 0.603000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.574000 seconds\n",
      "Retrying request to /chat/completions in 0.574000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 17, 1, 3, 7, 29, 2, 4, 5, 6, 8, 12, 16, 18, 20, 25, 11, 13, 14, 15, 24, 26, 27, 21, 22, 9, 10, 19, 23, 28]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.400000 seconds\n",
      "Retrying request to /chat/completions in 0.400000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.342000 seconds\n",
      "Retrying request to /chat/completions in 0.342000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.206000 seconds\n",
      "Retrying request to /chat/completions in 0.206000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.015000 seconds\n",
      "Retrying request to /chat/completions in 0.015000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.009000 seconds\n",
      "Retrying request to /chat/completions in 0.009000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.005000 seconds\n",
      "Retrying request to /chat/completions in 0.005000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.927000 seconds\n",
      "Retrying request to /chat/completions in 0.927000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.4342168779300788 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199797, Requested 2961. Please try again in 827ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.4342168779300788 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199797, Requested 2961. Please try again in 827ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.820000 seconds\n",
      "Retrying request to /chat/completions in 0.820000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.838000 seconds\n",
      "Retrying request to /chat/completions in 0.838000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.052122928142410374 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199768, Requested 2968. Please try again in 820ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.052122928142410374 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199768, Requested 2968. Please try again in 820ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.838000 seconds\n",
      "Retrying request to /chat/completions in 0.838000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.831000 seconds\n",
      "Retrying request to /chat/completions in 0.831000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.795000 seconds\n",
      "Retrying request to /chat/completions in 0.795000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.789000 seconds\n",
      "Retrying request to /chat/completions in 0.789000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.790000 seconds\n",
      "Retrying request to /chat/completions in 0.790000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  48%|████▊     | 105/220 [00:36<00:46,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.785000 seconds\n",
      "Retrying request to /chat/completions in 0.785000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.602000 seconds\n",
      "Retrying request to /chat/completions in 0.602000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.554000 seconds\n",
      "Retrying request to /chat/completions in 0.554000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.216000 seconds\n",
      "Retrying request to /chat/completions in 0.216000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 2, 6, 18, 3, 7, 8, 13, 14, 25, 4, 16, 17, 29, 12, 15, 26, 19, 20, 11, 28, 10, 9, 5, 23, 24, 27, 21, 22]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.720000 seconds\n",
      "Retrying request to /chat/completions in 0.720000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.878000 seconds\n",
      "Retrying request to /chat/completions in 0.878000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.886000 seconds\n",
      "Retrying request to /chat/completions in 0.886000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.861000 seconds\n",
      "Retrying request to /chat/completions in 0.861000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7624945283356872 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199746, Requested 3178. Please try again in 877ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7624945283356872 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199746, Requested 3178. Please try again in 877ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.862000 seconds\n",
      "Retrying request to /chat/completions in 0.862000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.892000 seconds\n",
      "Retrying request to /chat/completions in 0.892000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.884000 seconds\n",
      "Retrying request to /chat/completions in 0.884000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.848000 seconds\n",
      "Retrying request to /chat/completions in 0.848000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7376714590141247 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199574, Requested 3213. Please try again in 836ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7376714590141247 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199574, Requested 3213. Please try again in 836ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.788000 seconds\n",
      "Retrying request to /chat/completions in 0.788000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  48%|████▊     | 106/220 [00:37<01:10,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 2, 9, 15, 3, 6, 11, 20, 8, 26, 18, 1, 12, 16, 13, 14, 17, 7, 27, 28, 29, 4, 5, 10, 19, 21, 22, 23, 24, 25]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.173000 seconds\n",
      "Retrying request to /chat/completions in 0.173000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.056000 seconds\n",
      "Retrying request to /chat/completions in 0.056000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.060000 seconds\n",
      "Retrying request to /chat/completions in 0.060000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7382056108625408 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199942, Requested 3024. Please try again in 889ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7382056108625408 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199942, Requested 3024. Please try again in 889ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.885000 seconds\n",
      "Retrying request to /chat/completions in 0.885000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.6175832279840714 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199824, Requested 3151. Please try again in 892ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.6175832279840714 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199824, Requested 3151. Please try again in 892ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.664038183675232 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199793, Requested 3131. Please try again in 877ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.664038183675232 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199793, Requested 3131. Please try again in 877ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.2007386607666346 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199767, Requested 3155. Please try again in 876ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.2007386607666346 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199767, Requested 3155. Please try again in 876ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[157]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199734, Requested 3203. Please try again in 881ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[157]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199734, Requested 3203. Please try again in 881ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  49%|████▊     | 107/220 [00:38<01:06,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.5686045451831829 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199705, Requested 3179. Please try again in 865ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.5686045451831829 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199705, Requested 3179. Please try again in 865ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7308190191748545 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199618, Requested 2968. Please try again in 775ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7308190191748545 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199618, Requested 2968. Please try again in 775ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.781000 seconds\n",
      "Retrying request to /chat/completions in 0.781000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.778000 seconds\n",
      "Retrying request to /chat/completions in 0.778000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.011000 seconds\n",
      "Retrying request to /chat/completions in 0.011000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  49%|████▉     | 108/220 [00:38<00:56,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.755000 seconds\n",
      "Retrying request to /chat/completions in 0.755000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.696000 seconds\n",
      "Retrying request to /chat/completions in 0.696000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 4, 23, 29, 3, 21, 20, 16, 19, 10, 28, 12, 24, 27, 25, 14, 9, 8, 7, 6, 5, 2, 17, 18, 26, 22, 11, 13, 15]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.259000 seconds\n",
      "Retrying request to /chat/completions in 0.259000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.245000 seconds\n",
      "Retrying request to /chat/completions in 0.245000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.203000 seconds\n",
      "Retrying request to /chat/completions in 0.203000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.111000 seconds\n",
      "Retrying request to /chat/completions in 0.111000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.140000 seconds\n",
      "Retrying request to /chat/completions in 0.140000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.033000 seconds\n",
      "Retrying request to /chat/completions in 0.033000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.9427753876356594 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196967, Requested 3066. Please try again in 9ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.9427753876356594 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196967, Requested 3066. Please try again in 9ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  50%|████▉     | 109/220 [00:39<01:01,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.938000 seconds\n",
      "Retrying request to /chat/completions in 0.938000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.813000 seconds\n",
      "Retrying request to /chat/completions in 0.813000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.828000 seconds\n",
      "Retrying request to /chat/completions in 0.828000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.811000 seconds\n",
      "Retrying request to /chat/completions in 0.811000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.087000 seconds\n",
      "Retrying request to /chat/completions in 0.087000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.806000 seconds\n",
      "Retrying request to /chat/completions in 0.806000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.819000 seconds\n",
      "Retrying request to /chat/completions in 0.819000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.801000 seconds\n",
      "Retrying request to /chat/completions in 0.801000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.771000 seconds\n",
      "Retrying request to /chat/completions in 0.771000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.751000 seconds\n",
      "Retrying request to /chat/completions in 0.751000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 9, 3, 1, 6, 5, 20, 26, 8, 12, 10, 11, 21, 16, 15, 23, 7, 18, 27, 2, 14, 25, 4, 22, 28, 29, 17, 13, 19, 24]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.524000 seconds\n",
      "Retrying request to /chat/completions in 0.524000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  50%|█████     | 110/220 [00:39<01:05,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.205000 seconds\n",
      "Retrying request to /chat/completions in 0.205000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.168000 seconds\n",
      "Retrying request to /chat/completions in 0.168000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.165000 seconds\n",
      "Retrying request to /chat/completions in 0.165000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.173000 seconds\n",
      "Retrying request to /chat/completions in 0.173000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.169000 seconds\n",
      "Retrying request to /chat/completions in 0.169000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.160000 seconds\n",
      "Retrying request to /chat/completions in 0.160000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.151000 seconds\n",
      "Retrying request to /chat/completions in 0.151000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.127000 seconds\n",
      "Retrying request to /chat/completions in 0.127000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[124]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197343, Requested 3213. Please try again in 166ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[124]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197343, Requested 3213. Please try again in 166ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  50%|█████     | 111/220 [00:40<00:58,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.148000 seconds\n",
      "Retrying request to /chat/completions in 0.148000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.151000 seconds\n",
      "Retrying request to /chat/completions in 0.151000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.046000 seconds\n",
      "Retrying request to /chat/completions in 0.046000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.015000 seconds\n",
      "Retrying request to /chat/completions in 0.015000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[23]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199554, Requested 2968. Please try again in 756ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[23]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199554, Requested 2968. Please try again in 756ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  51%|█████     | 112/220 [00:40<00:48,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 1.354202802115203 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199493, Requested 3024. Please try again in 755ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 1.354202802115203 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199493, Requested 3024. Please try again in 755ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.757000 seconds\n",
      "Retrying request to /chat/completions in 0.757000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.03439491257207905 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199385, Requested 3131. Please try again in 754ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.03439491257207905 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199385, Requested 3131. Please try again in 754ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.15764795529574527 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199352, Requested 3179. Please try again in 759ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.15764795529574527 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199352, Requested 3179. Please try again in 759ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.9609140042055544 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199349, Requested 3155. Please try again in 751ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.9609140042055544 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199349, Requested 3155. Please try again in 751ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.2948958906472561 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199333, Requested 3167. Please try again in 750ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.2948958906472561 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199333, Requested 3167. Please try again in 750ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.752000 seconds\n",
      "Retrying request to /chat/completions in 0.752000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.050139910350325945 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199354, Requested 3151. Please try again in 751ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.050139910350325945 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199354, Requested 3151. Please try again in 751ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.754000 seconds\n",
      "Retrying request to /chat/completions in 0.754000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.644000 seconds\n",
      "Retrying request to /chat/completions in 0.644000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 3, 1, 4, 9, 8, 16, 15, 23, 5, 14, 11, 19, 13, 17, 7, 21, 18, 28, 6, 25, 26, 27, 12, 10, 2, 20, 22, 24, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.531000 seconds\n",
      "Retrying request to /chat/completions in 0.531000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.504000 seconds\n",
      "Retrying request to /chat/completions in 0.504000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  51%|█████▏    | 113/220 [00:40<00:42,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397000 seconds\n",
      "Retrying request to /chat/completions in 0.397000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.291000 seconds\n",
      "Retrying request to /chat/completions in 0.291000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.246000 seconds\n",
      "Retrying request to /chat/completions in 0.246000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.068000 seconds\n",
      "Retrying request to /chat/completions in 0.068000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.076000 seconds\n",
      "Retrying request to /chat/completions in 0.076000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.067000 seconds\n",
      "Retrying request to /chat/completions in 0.067000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.055000 seconds\n",
      "Retrying request to /chat/completions in 0.055000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.037000 seconds\n",
      "Retrying request to /chat/completions in 0.037000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.004000 seconds\n",
      "Retrying request to /chat/completions in 0.004000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.017000 seconds\n",
      "Retrying request to /chat/completions in 0.017000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.1949539784456117 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196832, Requested 3192. Please try again in 7ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.1949539784456117 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196832, Requested 3192. Please try again in 7ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.8799249261089762 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196814, Requested 3213. Please try again in 8ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.8799249261089762 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196814, Requested 3213. Please try again in 8ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.805000 seconds\n",
      "Retrying request to /chat/completions in 0.805000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.803000 seconds\n",
      "Retrying request to /chat/completions in 0.803000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.803000 seconds\n",
      "Retrying request to /chat/completions in 0.803000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.801000 seconds\n",
      "Retrying request to /chat/completions in 0.801000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.797000 seconds\n",
      "Retrying request to /chat/completions in 0.797000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.774000 seconds\n",
      "Retrying request to /chat/completions in 0.774000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  52%|█████▏    | 114/220 [00:41<00:56,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.657000 seconds\n",
      "Retrying request to /chat/completions in 0.657000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.541000 seconds\n",
      "Retrying request to /chat/completions in 0.541000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.527000 seconds\n",
      "Retrying request to /chat/completions in 0.527000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397000 seconds\n",
      "Retrying request to /chat/completions in 0.397000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.267000 seconds\n",
      "Retrying request to /chat/completions in 0.267000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 4, 2, 5, 6, 7, 8, 27, 3, 25, 1, 26, 28, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.736000 seconds\n",
      "Retrying request to /chat/completions in 0.736000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[57]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199206, Requested 3179. Please try again in 715ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.721000 seconds\n",
      "Exception raised in Job[57]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199206, Requested 3179. Please try again in 715ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Retrying request to /chat/completions in 0.721000 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  52%|█████▏    | 115/220 [00:42<01:05,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.717000 seconds\n",
      "Retrying request to /chat/completions in 0.717000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.09780713583687817 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199178, Requested 3167. Please try again in 703ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.09780713583687817 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199178, Requested 3167. Please try again in 703ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.697000 seconds\n",
      "Retrying request to /chat/completions in 0.697000 seconds\n",
      "ERROR:ragas.executor:Exception raised in Job[193]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199187, Requested 3151. Please try again in 701ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "Exception raised in Job[193]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199187, Requested 3151. Please try again in 701ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.716000 seconds\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "Retrying request to /chat/completions in 0.716000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.2018136514198151 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199152, Requested 3125. Please try again in 683ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.2018136514198151 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199152, Requested 3125. Please try again in 683ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "ERROR:ragas.executor:Exception raised in Job[159]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199165, Requested 3131. Please try again in 688ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[159]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199165, Requested 3131. Please try again in 688ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.9288227794487934 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199151, Requested 3163. Please try again in 694ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.9288227794487934 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199151, Requested 3163. Please try again in 694ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.732000 seconds\n",
      "Retrying request to /chat/completions in 0.732000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.640000 seconds\n",
      "Retrying request to /chat/completions in 0.640000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.483000 seconds\n",
      "Retrying request to /chat/completions in 0.483000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.399000 seconds\n",
      "Retrying request to /chat/completions in 0.399000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  54%|█████▎    | 118/220 [00:42<00:38,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.169000 seconds\n",
      "Retrying request to /chat/completions in 0.169000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.158000 seconds\n",
      "Retrying request to /chat/completions in 0.158000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.036000 seconds\n",
      "Retrying request to /chat/completions in 0.036000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.018000 seconds\n",
      "Retrying request to /chat/completions in 0.018000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.024000 seconds\n",
      "Retrying request to /chat/completions in 0.024000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.002000 seconds\n",
      "Retrying request to /chat/completions in 0.002000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[125]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199817, Requested 3024. Please try again in 852ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[125]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199817, Requested 3024. Please try again in 852ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  54%|█████▍    | 119/220 [00:43<00:38,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[91]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199683, Requested 3155. Please try again in 851ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[91]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199683, Requested 3155. Please try again in 851ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 6, 28, 3, 26, 17, 27, 9, 22, 8, 23, 7, 19, 20, 21, 5, 12, 13, 25, 2, 18, 10, 11, 16, 4, 14, 15, 29, 24]HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.3655946360834459 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199662, Requested 3193. Please try again in 856ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.3655946360834459 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199662, Requested 3193. Please try again in 856ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.058597138981227204 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199603, Requested 3192. Please try again in 838ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.058597138981227204 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199603, Requested 3192. Please try again in 838ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.777000 seconds\n",
      "Retrying request to /chat/completions in 0.777000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.815000 seconds\n",
      "Retrying request to /chat/completions in 0.815000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.830000 seconds\n",
      "Retrying request to /chat/completions in 0.830000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.760000 seconds\n",
      "Retrying request to /chat/completions in 0.760000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.750000 seconds\n",
      "Retrying request to /chat/completions in 0.750000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.760000 seconds\n",
      "Retrying request to /chat/completions in 0.760000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.615000 seconds\n",
      "Retrying request to /chat/completions in 0.615000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.582000 seconds\n",
      "Retrying request to /chat/completions in 0.582000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.537000 seconds\n",
      "Retrying request to /chat/completions in 0.537000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 4, 1, 11, 9, 26, 7, 3, 2, 5, 27, 25, 19, 17, 14, 28, 10, 16, 13, 15, 20, 8, 6, 12, 18, 24, 23, 21, 22, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.357000 seconds\n",
      "Retrying request to /chat/completions in 0.357000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.275000 seconds\n",
      "Retrying request to /chat/completions in 0.275000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.218000 seconds\n",
      "Retrying request to /chat/completions in 0.218000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  55%|█████▌    | 121/220 [00:44<00:40,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.945000 seconds\n",
      "Retrying request to /chat/completions in 0.945000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.921000 seconds\n",
      "Retrying request to /chat/completions in 0.921000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.910000 seconds\n",
      "Retrying request to /chat/completions in 0.910000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.921000 seconds\n",
      "Retrying request to /chat/completions in 0.921000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.899000 seconds\n",
      "Retrying request to /chat/completions in 0.899000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.900000 seconds\n",
      "Retrying request to /chat/completions in 0.900000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.078000 seconds\n",
      "Retrying request to /chat/completions in 0.078000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.840000 seconds\n",
      "Retrying request to /chat/completions in 0.840000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.842000 seconds\n",
      "Retrying request to /chat/completions in 0.842000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.806000 seconds\n",
      "Retrying request to /chat/completions in 0.806000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.794000 seconds\n",
      "Retrying request to /chat/completions in 0.794000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.778000 seconds\n",
      "Retrying request to /chat/completions in 0.778000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [12, 0, 4, 9, 5, 10, 11, 21, 22, 25, 7, 17, 15, 1, 2, 14, 8, 6, 18, 24, 16, 27, 28, 26, 3, 23, 20, 29, 19, 13]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  55%|█████▌    | 122/220 [00:45<00:46,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.244000 seconds\n",
      "Retrying request to /chat/completions in 0.244000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 1.3456396715663992 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199808, Requested 3125. Please try again in 879ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 1.3456396715663992 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199808, Requested 3125. Please try again in 879ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.884000 seconds\n",
      "Retrying request to /chat/completions in 0.884000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[58]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199767, Requested 3167. Please try again in 880ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[58]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199767, Requested 3167. Please try again in 880ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  56%|█████▌    | 123/220 [00:45<00:44,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.07312990917981355 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199754, Requested 3176. Please try again in 879ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.07312990917981355 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199754, Requested 3176. Please try again in 879ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.874000 seconds\n",
      "Retrying request to /chat/completions in 0.874000 seconds\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.005851185893698152 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199758, Requested 3168. Please try again in 877ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.005851185893698152 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199758, Requested 3168. Please try again in 877ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.883000 seconds\n",
      "Retrying request to /chat/completions in 0.883000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.6460727016016414 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199714, Requested 3207. Please try again in 876ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.6460727016016414 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199714, Requested 3207. Please try again in 876ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7927880352431456 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199717, Requested 3226. Please try again in 882ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7927880352431456 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199717, Requested 3226. Please try again in 882ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.868000 seconds\n",
      "Retrying request to /chat/completions in 0.868000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.109000 seconds\n",
      "Retrying request to /chat/completions in 0.109000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.783000 seconds\n",
      "Retrying request to /chat/completions in 0.783000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.712000 seconds\n",
      "Retrying request to /chat/completions in 0.712000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.659000 seconds\n",
      "Retrying request to /chat/completions in 0.659000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.634000 seconds\n",
      "Retrying request to /chat/completions in 0.634000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 3, 1, 5, 4, 2, 14, 24, 21, 25, 19, 27, 13, 17, 9, 15, 20, 28, 26, 29, 11, 18, 23, 8, 6, 7, 12, 10, 16, 22]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.228000 seconds\n",
      "Retrying request to /chat/completions in 0.228000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.100000 seconds\n",
      "Retrying request to /chat/completions in 0.100000 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  56%|█████▋    | 124/220 [00:46<00:55,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.017000 seconds\n",
      "Retrying request to /chat/completions in 0.017000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.5140166015838459 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196879, Requested 3163. Please try again in 12ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.5140166015838459 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196879, Requested 3163. Please try again in 12ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.010000 seconds\n",
      "Retrying request to /chat/completions in 0.010000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.38232880633024735 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196837, Requested 3219. Please try again in 16ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.38232880633024735 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196837, Requested 3219. Please try again in 16ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[194]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196883, Requested 3192. Please try again in 22ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[194]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196883, Requested 3192. Please try again in 22ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.6057823225506958 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 200000, Requested 3193. Please try again in 957ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.6057823225506958 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 200000, Requested 3193. Please try again in 957ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.133000 seconds\n",
      "Retrying request to /chat/completions in 0.133000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.844000 seconds\n",
      "Retrying request to /chat/completions in 0.844000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.847000 seconds\n",
      "Retrying request to /chat/completions in 0.847000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.846000 seconds\n",
      "Retrying request to /chat/completions in 0.846000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.776000 seconds\n",
      "Retrying request to /chat/completions in 0.776000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.795000 seconds\n",
      "Retrying request to /chat/completions in 0.795000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.769000 seconds\n",
      "Retrying request to /chat/completions in 0.769000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.785000 seconds\n",
      "Retrying request to /chat/completions in 0.785000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.674000 seconds\n",
      "Retrying request to /chat/completions in 0.674000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.660000 seconds\n",
      "Retrying request to /chat/completions in 0.660000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.519000 seconds\n",
      "Retrying request to /chat/completions in 0.519000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.406000 seconds\n",
      "Retrying request to /chat/completions in 0.406000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 29, 4, 5, 3, 8, 9, 26, 25, 6, 1, 18, 21, 24, 20, 10, 11, 12, 13, 14, 15, 16, 17, 2, 7, 19, 22, 27, 28, 23]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  57%|█████▋    | 126/220 [00:47<00:51,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.005000 seconds\n",
      "Retrying request to /chat/completions in 0.005000 seconds\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 1.9936734369445328 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196908, Requested 3176. Please try again in 25ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 1.9936734369445328 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196908, Requested 3176. Please try again in 25ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.016000 seconds\n",
      "Retrying request to /chat/completions in 0.016000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 1.646879973773476 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196876, Requested 3168. Please try again in 13ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 1.646879973773476 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196876, Requested 3168. Please try again in 13ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.023000 seconds\n",
      "Retrying request to /chat/completions in 0.023000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.012000 seconds\n",
      "Retrying request to /chat/completions in 0.012000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.013000 seconds\n",
      "Retrying request to /chat/completions in 0.013000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.4716253510728363 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199545, Requested 3147. Please try again in 807ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.4716253510728363 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199545, Requested 3147. Please try again in 807ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.801000 seconds\n",
      "Retrying request to /chat/completions in 0.801000 seconds\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.06543553791624945 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199528, Requested 3207. Please try again in 820ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.06543553791624945 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199528, Requested 3207. Please try again in 820ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 1.9606381479392925 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199503, Requested 3226. Please try again in 818ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 1.9606381479392925 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199503, Requested 3226. Please try again in 818ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.008000 seconds\n",
      "Retrying request to /chat/completions in 0.008000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.746000 seconds\n",
      "Retrying request to /chat/completions in 0.746000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.740000 seconds\n",
      "Retrying request to /chat/completions in 0.740000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.727000 seconds\n",
      "Retrying request to /chat/completions in 0.727000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.732000 seconds\n",
      "Retrying request to /chat/completions in 0.732000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 2, 7, 11, 12, 17, 22, 28, 4, 5, 6, 10, 14, 13, 24, 8, 18, 27, 26, 25, 23, 9, 19, 29, 1, 3, 15, 16, 20, 21]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.790000 seconds\n",
      "Retrying request to /chat/completions in 0.790000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498000 seconds\n",
      "Retrying request to /chat/completions in 0.498000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.486000 seconds\n",
      "Retrying request to /chat/completions in 0.486000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  58%|█████▊    | 127/220 [00:48<00:57,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.300000 seconds\n",
      "Retrying request to /chat/completions in 0.300000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.176000 seconds\n",
      "Retrying request to /chat/completions in 0.176000 seconds\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.23316499845798033 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197459, Requested 3138. Please try again in 179ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.23316499845798033 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197459, Requested 3138. Please try again in 179ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.172000 seconds\n",
      "Retrying request to /chat/completions in 0.172000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.145000 seconds\n",
      "Retrying request to /chat/completions in 0.145000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.069000 seconds\n",
      "Retrying request to /chat/completions in 0.069000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.091000 seconds\n",
      "Retrying request to /chat/completions in 0.091000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.051000 seconds\n",
      "Retrying request to /chat/completions in 0.051000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.065000 seconds\n",
      "Retrying request to /chat/completions in 0.065000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.887375 seconds\n",
      "Retrying request to /chat/completions in 0.887375 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  58%|█████▊    | 128/220 [00:48<00:56,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.744000 seconds\n",
      "Retrying request to /chat/completions in 0.744000 seconds\n",
      "ERROR:ragas.executor:Exception raised in Job[93]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199353, Requested 3125. Please try again in 743ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[93]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199353, Requested 3125. Please try again in 743ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[25]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199387, Requested 3163. Please try again in 765ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[25]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199387, Requested 3163. Please try again in 765ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.5199036322691759 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199267, Requested 3219. Please try again in 745ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.5199036322691759 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199267, Requested 3219. Please try again in 745ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[59]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199302, Requested 3193. Please try again in 748ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[59]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199302, Requested 3193. Please try again in 748ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.739000 seconds\n",
      "Retrying request to /chat/completions in 0.739000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.654000 seconds\n",
      "Retrying request to /chat/completions in 0.654000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.624000 seconds\n",
      "Retrying request to /chat/completions in 0.624000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.269000 seconds\n",
      "Retrying request to /chat/completions in 0.269000 seconds\n",
      "After Reranking, new rank list for nodes: [0, 17, 5, 2, 8, 28, 27, 13, 20, 23, 24, 18, 21, 16, 9, 7, 6, 10, 14, 12, 11, 15, 26, 3, 1, 4, 25, 19, 22, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.054000 seconds\n",
      "Retrying request to /chat/completions in 0.054000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.012000 seconds\n",
      "Retrying request to /chat/completions in 0.012000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.024000 seconds\n",
      "Retrying request to /chat/completions in 0.024000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.158000 seconds\n",
      "Retrying request to /chat/completions in 0.158000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.110000 seconds\n",
      "Retrying request to /chat/completions in 0.110000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.062000 seconds\n",
      "Retrying request to /chat/completions in 0.062000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.064000 seconds\n",
      "Retrying request to /chat/completions in 0.064000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.064000 seconds\n",
      "Retrying request to /chat/completions in 0.064000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.038000 seconds\n",
      "Retrying request to /chat/completions in 0.038000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 1.5922603809944833 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199995, Requested 3147. Please try again in 942ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 1.5922603809944833 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199995, Requested 3147. Please try again in 942ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7304410275823594 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199968, Requested 3232. Please try again in 960ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.941000 seconds\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7304410275823594 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199968, Requested 3232. Please try again in 960ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "Retrying request to /chat/completions in 0.941000 seconds\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.958000 seconds\n",
      "Retrying request to /chat/completions in 0.958000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.930000 seconds\n",
      "Retrying request to /chat/completions in 0.930000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.833000 seconds\n",
      "Retrying request to /chat/completions in 0.833000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.825000 seconds\n",
      "Retrying request to /chat/completions in 0.825000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.832000 seconds\n",
      "Retrying request to /chat/completions in 0.832000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.851000 seconds\n",
      "Retrying request to /chat/completions in 0.851000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.830000 seconds\n",
      "Retrying request to /chat/completions in 0.830000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.821000 seconds\n",
      "Retrying request to /chat/completions in 0.821000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  60%|██████    | 132/220 [00:50<00:39,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.278000 seconds\n",
      "Retrying request to /chat/completions in 0.278000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.260000 seconds\n",
      "Retrying request to /chat/completions in 0.260000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.003000 seconds\n",
      "Retrying request to /chat/completions in 0.003000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.820000 seconds\n",
      "Retrying request to /chat/completions in 0.820000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.809000 seconds\n",
      "Retrying request to /chat/completions in 0.809000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.9756902431002142 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199415, Requested 3125. Please try again in 762ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.757000 seconds\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.9756902431002142 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199415, Requested 3125. Please try again in 762ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying request to /chat/completions in 0.757000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.754000 seconds\n",
      "Retrying request to /chat/completions in 0.754000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[162]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199328, Requested 3219. Please try again in 764ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[162]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199328, Requested 3219. Please try again in 764ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  60%|██████    | 133/220 [00:50<00:41,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[26]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199312, Requested 3207. Please try again in 755ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[26]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199312, Requested 3207. Please try again in 755ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[195]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199315, Requested 3168. Please try again in 744ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[195]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199315, Requested 3168. Please try again in 744ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.738000 seconds\n",
      "Retrying request to /chat/completions in 0.738000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.012558866643539224 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199268, Requested 3175. Please try again in 732ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.012558866643539224 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199268, Requested 3175. Please try again in 732ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.742000 seconds\n",
      "Retrying request to /chat/completions in 0.742000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.758000 seconds\n",
      "Retrying request to /chat/completions in 0.758000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 2, 1, 5, 4, 3, 12, 13, 14, 20, 19, 26, 25, 8, 22, 29, 21, 18, 17, 11, 27, 15, 28, 6, 7, 9, 10, 16, 23, 24]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.192000 seconds\n",
      "Retrying request to /chat/completions in 0.192000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.178000 seconds\n",
      "Retrying request to /chat/completions in 0.178000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.181000 seconds\n",
      "Retrying request to /chat/completions in 0.181000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  62%|██████▏   | 136/220 [00:51<00:32,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.019000 seconds\n",
      "Retrying request to /chat/completions in 0.019000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[94]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199935, Requested 3176. Please try again in 933ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[94]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199935, Requested 3176. Please try again in 933ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.48482447119176075 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199914, Requested 3174. Please try again in 926ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.48482447119176075 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199914, Requested 3174. Please try again in 926ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.938000 seconds\n",
      "Retrying request to /chat/completions in 0.938000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.921000 seconds\n",
      "Retrying request to /chat/completions in 0.921000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.926000 seconds\n",
      "Retrying request to /chat/completions in 0.926000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.817000 seconds\n",
      "Retrying request to /chat/completions in 0.817000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.794000 seconds\n",
      "Retrying request to /chat/completions in 0.794000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.798000 seconds\n",
      "Retrying request to /chat/completions in 0.798000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.755000 seconds\n",
      "Retrying request to /chat/completions in 0.755000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.048000 seconds\n",
      "Retrying request to /chat/completions in 0.048000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.781000 seconds\n",
      "Retrying request to /chat/completions in 0.781000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.752000 seconds\n",
      "Retrying request to /chat/completions in 0.752000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.691000 seconds\n",
      "Retrying request to /chat/completions in 0.691000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.467000 seconds\n",
      "Retrying request to /chat/completions in 0.467000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  63%|██████▎   | 138/220 [00:52<00:33,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.010000 seconds\n",
      "Retrying request to /chat/completions in 0.010000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.014000 seconds\n",
      "Retrying request to /chat/completions in 0.014000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.860863 seconds\n",
      "Retrying request to /chat/completions in 0.860863 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.009000 seconds\n",
      "Retrying request to /chat/completions in 0.009000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.005000 seconds\n",
      "Retrying request to /chat/completions in 0.005000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.019000 seconds\n",
      "Retrying request to /chat/completions in 0.019000 seconds\n",
      "ERROR:ragas.executor:Exception raised in Job[161]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199967, Requested 3226. Please try again in 957ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[161]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199967, Requested 3226. Please try again in 957ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  63%|██████▎   | 139/220 [00:52<00:30,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 1.8891748379553177 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199912, Requested 3232. Please try again in 943ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 1.8891748379553177 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199912, Requested 3232. Please try again in 943ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.8965930144381711 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199942, Requested 3228. Please try again in 951ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.8965930144381711 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199942, Requested 3228. Please try again in 951ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.825000 seconds\n",
      "Retrying request to /chat/completions in 0.825000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.8261936455536019 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199589, Requested 3175. Please try again in 829ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.8261936455536019 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199589, Requested 3175. Please try again in 829ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.38376665359337847 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199569, Requested 3187. Please try again in 826ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.38376665359337847 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199569, Requested 3187. Please try again in 826ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.4061616753920342 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199863, Requested 3149. Please try again in 903ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.4061616753920342 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199863, Requested 3149. Please try again in 903ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "ERROR:ragas.executor:Exception raised in Job[27]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199860, Requested 3147. Please try again in 902ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[27]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199860, Requested 3147. Please try again in 902ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  64%|██████▎   | 140/220 [00:52<00:27,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.910000 seconds\n",
      "Retrying request to /chat/completions in 0.910000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.721000 seconds\n",
      "Retrying request to /chat/completions in 0.721000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.699000 seconds\n",
      "Retrying request to /chat/completions in 0.699000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 3, 1, 2, 5, 4, 6, 8, 9, 10, 16, 17, 18, 22, 23, 24, 25, 26, 27, 29, 12, 15, 20, 19, 13, 28, 7, 11, 14, 21]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.430000 seconds\n",
      "Retrying request to /chat/completions in 0.430000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.441000 seconds\n",
      "Retrying request to /chat/completions in 0.441000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.303000 seconds\n",
      "Retrying request to /chat/completions in 0.303000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.271000 seconds\n",
      "Retrying request to /chat/completions in 0.271000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.828067064178709 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197012, Requested 3038. Please try again in 15ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.828067064178709 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197012, Requested 3038. Please try again in 15ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.941000 seconds\n",
      "Retrying request to /chat/completions in 0.941000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.836000 seconds\n",
      "Retrying request to /chat/completions in 0.836000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.837000 seconds\n",
      "Retrying request to /chat/completions in 0.837000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.824000 seconds\n",
      "Retrying request to /chat/completions in 0.824000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.821000 seconds\n",
      "Retrying request to /chat/completions in 0.821000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.801000 seconds\n",
      "Retrying request to /chat/completions in 0.801000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.796000 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  64%|██████▍   | 141/220 [00:53<00:39,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying request to /chat/completions in 0.796000 seconds\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.2130838773560486 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199461, Requested 3125. Please try again in 775ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.2130838773560486 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199461, Requested 3125. Please try again in 775ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.746000 seconds\n",
      "Retrying request to /chat/completions in 0.746000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.592000 seconds\n",
      "Retrying request to /chat/completions in 0.592000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  65%|██████▍   | 142/220 [00:54<00:42,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.140000 seconds\n",
      "Retrying request to /chat/completions in 0.140000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.161000 seconds\n",
      "Retrying request to /chat/completions in 0.161000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.091000 seconds\n",
      "Retrying request to /chat/completions in 0.091000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 1.6814166709100313 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197055, Requested 3174. Please try again in 68ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 1.6814166709100313 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197055, Requested 3174. Please try again in 68ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.033000 seconds\n",
      "Retrying request to /chat/completions in 0.033000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.039000 seconds\n",
      "Retrying request to /chat/completions in 0.039000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.030000 seconds\n",
      "Retrying request to /chat/completions in 0.030000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.037000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.034000 seconds\n",
      "Retrying request to /chat/completions in 0.037000 seconds\n",
      "Retrying request to /chat/completions in 0.034000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.027000 seconds\n",
      "Retrying request to /chat/completions in 0.027000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.024000 seconds\n",
      "Retrying request to /chat/completions in 0.024000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.5087210556015385 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199537, Requested 3124. Please try again in 798ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.5087210556015385 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199537, Requested 3124. Please try again in 798ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7650281450641092 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199526, Requested 3086. Please try again in 783ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7650281450641092 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199526, Requested 3086. Please try again in 783ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 1.7690574905997438 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199496, Requested 3149. Please try again in 793ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 1.7690574905997438 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199496, Requested 3149. Please try again in 793ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "After Reranking, new rank list for nodes: [0, 1, 2, 8, 10, 12, 13, 18, 19, 20, 23, 24, 11, 14, 17, 9, 28, 25, 27, 5, 7, 21, 15, 16, 3, 4, 6, 22, 26, 29]HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.802000 seconds\n",
      "Retrying request to /chat/completions in 0.802000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.1247651702304895 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199296, Requested 3185. Please try again in 744ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.1247651702304895 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199296, Requested 3185. Please try again in 744ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.5075183087585992 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199300, Requested 3174. Please try again in 742ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.5075183087585992 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199300, Requested 3174. Please try again in 742ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.714000 seconds\n",
      "Retrying request to /chat/completions in 0.714000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.746000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.746000 seconds\n",
      "Retrying request to /chat/completions in 0.746000 seconds\n",
      "Retrying request to /chat/completions in 0.746000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 1.8464068701176777 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199241, Requested 3187. Please try again in 728ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 1.8464068701176777 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199241, Requested 3187. Please try again in 728ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468000 seconds\n",
      "Retrying request to /chat/completions in 0.468000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 2, 6, 9, 14, 15, 16, 19, 20, 21, 24, 25, 26, 3, 11, 12, 13, 17, 4, 5, 7, 10, 27, 8, 18, 22, 23, 28, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.222000 seconds\n",
      "Retrying request to /chat/completions in 0.222000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.237000 seconds\n",
      "Retrying request to /chat/completions in 0.237000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.026000 seconds\n",
      "Retrying request to /chat/completions in 0.026000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.027000 seconds\n",
      "Retrying request to /chat/completions in 0.027000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.003000 seconds\n",
      "Retrying request to /chat/completions in 0.003000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 1.6036812265642668 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196814, Requested 3228. Please try again in 12ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 1.6036812265642668 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196814, Requested 3228. Please try again in 12ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.910000 seconds\n",
      "Retrying request to /chat/completions in 0.910000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[96]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199587, Requested 3125. Please try again in 813ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[96]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199587, Requested 3125. Please try again in 813ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.810000 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  65%|██████▌   | 143/220 [00:56<00:57,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying request to /chat/completions in 0.810000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.807000 seconds\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "Retrying request to /chat/completions in 0.807000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.808000 seconds\n",
      "Retrying request to /chat/completions in 0.808000 seconds\n",
      "ERROR:ragas.executor:Exception raised in Job[163]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199472, Requested 3232. Please try again in 811ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[163]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199472, Requested 3232. Please try again in 811ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.817000 seconds\n",
      "Retrying request to /chat/completions in 0.817000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.460000 seconds\n",
      "Retrying request to /chat/completions in 0.460000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.353000 seconds\n",
      "Retrying request to /chat/completions in 0.353000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.187000 seconds\n",
      "Retrying request to /chat/completions in 0.187000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.092000 seconds\n",
      "Retrying request to /chat/completions in 0.092000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.059000 seconds\n",
      "Retrying request to /chat/completions in 0.059000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.8810963583632344 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197008, Requested 3186. Please try again in 58ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.8810963583632344 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197008, Requested 3186. Please try again in 58ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 21, 16, 10, 3, 6, 14, 9, 23, 17, 11, 15, 12, 7, 4, 5, 2, 25, 20, 26, 22, 29, 1, 8, 19, 13, 24, 27, 28, 18]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.934000 seconds\n",
      "Retrying request to /chat/completions in 0.934000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.908000 seconds\n",
      "Retrying request to /chat/completions in 0.908000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 1.5899480869744707 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199546, Requested 3124. Please try again in 801ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 1.5899480869744707 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199546, Requested 3124. Please try again in 801ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  66%|██████▋   | 146/220 [00:57<00:40,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.772000 seconds\n",
      "Retrying request to /chat/completions in 0.772000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.771000 seconds\n",
      "Retrying request to /chat/completions in 0.771000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.753000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.779000 seconds\n",
      "Retrying request to /chat/completions in 0.753000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.759000 seconds\n",
      "Retrying request to /chat/completions in 0.779000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.772000 seconds\n",
      "Retrying request to /chat/completions in 0.759000 seconds\n",
      "Retrying request to /chat/completions in 0.772000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.604000 seconds\n",
      "Retrying request to /chat/completions in 0.604000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.244000 seconds\n",
      "Retrying request to /chat/completions in 0.244000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 7, 4, 29, 2, 3, 9, 13, 16, 24, 25, 10, 11, 12, 14, 15, 18, 20, 23, 28, 19, 27, 17, 26, 21, 8, 1, 5, 6, 22]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.035000 seconds\n",
      "Retrying request to /chat/completions in 0.035000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.060000 seconds\n",
      "Retrying request to /chat/completions in 0.060000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.041000 seconds\n",
      "Retrying request to /chat/completions in 0.041000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.010000 seconds\n",
      "Retrying request to /chat/completions in 0.010000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.016000 seconds\n",
      "Retrying request to /chat/completions in 0.016000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.039000 seconds\n",
      "Retrying request to /chat/completions in 0.039000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.017000 seconds\n",
      "Retrying request to /chat/completions in 0.017000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.010000 seconds\n",
      "Retrying request to /chat/completions in 0.010000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.012000 seconds\n",
      "Retrying request to /chat/completions in 0.012000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.012000 seconds\n",
      "Retrying request to /chat/completions in 0.012000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.5721306999822902 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199754, Requested 3107. Please try again in 858ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.836000 seconds\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.5721306999822902 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199754, Requested 3107. Please try again in 858ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying request to /chat/completions in 0.836000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.6435374962689305 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199628, Requested 3154. Please try again in 834ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.6435374962689305 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199628, Requested 3154. Please try again in 834ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[63]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199627, Requested 3149. Please try again in 832ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[63]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199627, Requested 3149. Please try again in 832ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.844000 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  67%|██████▋   | 147/220 [00:58<00:47,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying request to /chat/completions in 0.844000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.544662594947092 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199604, Requested 3193. Please try again in 839ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.544662594947092 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199604, Requested 3193. Please try again in 839ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[197]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199595, Requested 3174. Please try again in 830ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[197]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199595, Requested 3174. Please try again in 830ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.831000 seconds\n",
      "Retrying request to /chat/completions in 0.831000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.819000 seconds\n",
      "Retrying request to /chat/completions in 0.819000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.801000 seconds\n",
      "Retrying request to /chat/completions in 0.801000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  68%|██████▊   | 149/220 [00:58<00:33,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 6, 12, 2, 3, 4, 11, 22, 13, 29, 10, 9, 7, 8, 14, 26, 25, 5, 24, 16, 23, 21, 15, 1, 28, 27, 20, 19, 18, 17]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.434000 seconds\n",
      "Retrying request to /chat/completions in 0.434000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  68%|██████▊   | 150/220 [00:58<00:30,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.184000 seconds\n",
      "Retrying request to /chat/completions in 0.184000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.170000 seconds\n",
      "Retrying request to /chat/completions in 0.170000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.360000 seconds\n",
      "Retrying request to /chat/completions in 0.360000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.326000 seconds\n",
      "Retrying request to /chat/completions in 0.326000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.014831576052240725 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197408, Requested 3097. Please try again in 151ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.014831576052240725 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197408, Requested 3097. Please try again in 151ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.37392574949037327 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197352, Requested 3189. Please try again in 162ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.37392574949037327 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197352, Requested 3189. Please try again in 162ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.154000 seconds\n",
      "Retrying request to /chat/completions in 0.154000 seconds\n",
      "ERROR:ragas.executor:Exception raised in Job[164]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197311, Requested 3228. Please try again in 161ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.109000 seconds\n",
      "Exception raised in Job[164]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197311, Requested 3228. Please try again in 161ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "ERROR:ragas.executor:Exception raised in Job[198]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197288, Requested 3187. Please try again in 142ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Retrying request to /chat/completions in 0.109000 seconds\n",
      "Exception raised in Job[198]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197288, Requested 3187. Please try again in 142ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  69%|██████▊   | 151/220 [00:59<00:29,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.060000 seconds\n",
      "Retrying request to /chat/completions in 0.060000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.079000 seconds\n",
      "Retrying request to /chat/completions in 0.079000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.886000 seconds\n",
      "Retrying request to /chat/completions in 0.886000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.864000 seconds\n",
      "Retrying request to /chat/completions in 0.864000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.863000 seconds\n",
      "Retrying request to /chat/completions in 0.863000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.856000 seconds\n",
      "Retrying request to /chat/completions in 0.856000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.813000 seconds\n",
      "Retrying request to /chat/completions in 0.813000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.816000 seconds\n",
      "Retrying request to /chat/completions in 0.816000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.806000 seconds\n",
      "Retrying request to /chat/completions in 0.806000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.784000 seconds\n",
      "Retrying request to /chat/completions in 0.784000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.792000 seconds\n",
      "Retrying request to /chat/completions in 0.792000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  70%|██████▉   | 153/220 [00:59<00:20,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 1.312256689047227 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199250, Requested 3186. Please try again in 730ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 1.312256689047227 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199250, Requested 3186. Please try again in 730ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491000 seconds\n",
      "Retrying request to /chat/completions in 0.491000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 2, 3, 1, 7, 8, 6, 9, 4, 11, 5, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 12, 25, 26, 23, 29, 24, 22, 27, 28]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.010000 seconds\n",
      "Retrying request to /chat/completions in 0.010000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.071000 seconds\n",
      "Retrying request to /chat/completions in 0.071000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.036000 seconds\n",
      "Retrying request to /chat/completions in 0.036000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[131]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196905, Requested 3124. Please try again in 8ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[131]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196905, Requested 3124. Please try again in 8ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.004000 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  70%|███████   | 154/220 [01:00<00:28,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying request to /chat/completions in 0.004000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 1.933405 seconds\n",
      "Retrying request to /chat/completions in 1.933405 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.001000 seconds\n",
      "Retrying request to /chat/completions in 0.001000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.004000 seconds\n",
      "Retrying request to /chat/completions in 0.004000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.006000 seconds\n",
      "Retrying request to /chat/completions in 0.006000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.947000 seconds\n",
      "Retrying request to /chat/completions in 0.947000 seconds\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.8764383389405459 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 200000, Requested 3193. Please try again in 957ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.8764383389405459 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 200000, Requested 3193. Please try again in 957ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.843000 seconds\n",
      "Retrying request to /chat/completions in 0.843000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.823000 seconds\n",
      "Retrying request to /chat/completions in 0.823000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.823000 seconds\n",
      "Retrying request to /chat/completions in 0.823000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.09094037963707158 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199532, Requested 3154. Please try again in 805ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.09094037963707158 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199532, Requested 3154. Please try again in 805ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.813000 seconds\n",
      "Retrying request to /chat/completions in 0.813000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.801000 seconds\n",
      "Retrying request to /chat/completions in 0.801000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.757000 seconds\n",
      "Retrying request to /chat/completions in 0.757000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.543000 seconds\n",
      "Retrying request to /chat/completions in 0.543000 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  70%|███████   | 155/220 [01:00<00:27,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.306000 seconds\n",
      "After Reranking, new rank list for nodes: [0, 2, 11, 23, 27, 29, 8, 17, 14, 16, 20, 21, 25, 26, 28, 24, 18, 13, 10, 6, 4, 1, 3, 12, 7, 22, 15, 5, 9, 19]Retrying request to /chat/completions in 0.306000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.359000 seconds\n",
      "Retrying request to /chat/completions in 0.359000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7737499787819089 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199377, Requested 3125. Please try again in 750ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7737499787819089 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199377, Requested 3125. Please try again in 750ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.8265152005989033 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199360, Requested 3094. Please try again in 736ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.8265152005989033 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199360, Requested 3094. Please try again in 736ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.763000 seconds\n",
      "Retrying request to /chat/completions in 0.763000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.727000 seconds\n",
      "Retrying request to /chat/completions in 0.727000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.2797572367405132 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199325, Requested 3118. Please try again in 732ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.2797572367405132 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199325, Requested 3118. Please try again in 732ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.8438046133194953 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199305, Requested 3190. Please try again in 748ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.8438046133194953 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199305, Requested 3190. Please try again in 748ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 1.8341364458908698 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199308, Requested 3189. Please try again in 749ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 1.8341364458908698 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199308, Requested 3189. Please try again in 749ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.741000 seconds\n",
      "Retrying request to /chat/completions in 0.741000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.735000 seconds\n",
      "Retrying request to /chat/completions in 0.735000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.677000 seconds\n",
      "Retrying request to /chat/completions in 0.677000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.471000 seconds\n",
      "Retrying request to /chat/completions in 0.471000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  71%|███████   | 156/220 [01:02<00:44,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.017000 seconds\n",
      "Retrying request to /chat/completions in 0.017000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.024000 seconds\n",
      "Retrying request to /chat/completions in 0.024000 seconds\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.02697823762602858 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196908, Requested 3183. Please try again in 27ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.02697823762602858 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196908, Requested 3183. Please try again in 27ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.034000 seconds\n",
      "Retrying request to /chat/completions in 0.034000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.027000 seconds\n",
      "Retrying request to /chat/completions in 0.027000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.840000 seconds\n",
      "Retrying request to /chat/completions in 0.840000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 1.20409007758613 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199636, Requested 3107. Please try again in 822ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 1.20409007758613 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199636, Requested 3107. Please try again in 822ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.844000 seconds\n",
      "Retrying request to /chat/completions in 0.844000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.816000 seconds\n",
      "Retrying request to /chat/completions in 0.816000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 15, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.11986669565298547 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199358, Requested 3073. Please try again in 729ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.11986669565298547 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199358, Requested 3073. Please try again in 729ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.735000 seconds\n",
      "Retrying request to /chat/completions in 0.735000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[98]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199285, Requested 3186. Please try again in 741ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[98]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199285, Requested 3186. Please try again in 741ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.743000 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  71%|███████▏  | 157/220 [01:02<00:36,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying request to /chat/completions in 0.743000 seconds\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.301967311709161 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199264, Requested 3121. Please try again in 715ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.301967311709161 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199264, Requested 3121. Please try again in 715ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.735000 seconds\n",
      "Retrying request to /chat/completions in 0.735000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.615000 seconds\n",
      "Retrying request to /chat/completions in 0.615000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468000 seconds\n",
      "Retrying request to /chat/completions in 0.468000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.435000 seconds\n",
      "Retrying request to /chat/completions in 0.435000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 4, 5, 2, 1, 3, 6, 18, 19, 13, 20, 21, 23, 22, 24, 25, 26, 8, 14, 15, 27, 28, 29, 12, 7, 9, 16, 17, 10, 11]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.007000 seconds\n",
      "Retrying request to /chat/completions in 0.007000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.014000 seconds\n",
      "Retrying request to /chat/completions in 0.014000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.933000 seconds\n",
      "Retrying request to /chat/completions in 0.933000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[166]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199914, Requested 3193. Please try again in 932ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[166]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199914, Requested 3193. Please try again in 932ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  72%|███████▏  | 158/220 [01:03<00:40,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.893000 seconds\n",
      "Retrying request to /chat/completions in 0.893000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.874000 seconds\n",
      "Retrying request to /chat/completions in 0.874000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.886000 seconds\n",
      "Retrying request to /chat/completions in 0.886000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.860000 seconds\n",
      "Retrying request to /chat/completions in 0.860000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.851000 seconds\n",
      "Retrying request to /chat/completions in 0.851000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.033000 seconds\n",
      "Retrying request to /chat/completions in 0.033000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.804000 seconds\n",
      "Retrying request to /chat/completions in 0.804000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.752000 seconds\n",
      "Retrying request to /chat/completions in 0.752000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.636000 seconds\n",
      "Retrying request to /chat/completions in 0.636000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 1.2042476192603173 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199461, Requested 3073. Please try again in 760ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 1.2042476192603173 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199461, Requested 3073. Please try again in 760ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.660000 seconds\n",
      "Retrying request to /chat/completions in 0.660000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 2, 4, 3, 6, 1, 20, 19, 21, 5, 24, 10, 16, 15, 14, 13, 8, 7, 12, 18, 11, 9, 25, 23, 26, 17, 22, 27, 28, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.440000 seconds\n",
      "Retrying request to /chat/completions in 0.440000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.443000 seconds\n",
      "Retrying request to /chat/completions in 0.443000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.420000 seconds\n",
      "Retrying request to /chat/completions in 0.420000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.421000 seconds\n",
      "Retrying request to /chat/completions in 0.421000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.420000 seconds\n",
      "Retrying request to /chat/completions in 0.420000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.414000 seconds\n",
      "Retrying request to /chat/completions in 0.414000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.6100542823500862 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.6100542823500862 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413000 seconds\n",
      "Retrying request to /chat/completions in 0.413000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.246000 seconds\n",
      "Retrying request to /chat/completions in 0.246000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  73%|███████▎  | 160/220 [01:04<00:38,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.341000 seconds\n",
      "Retrying request to /chat/completions in 0.341000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.147000 seconds\n",
      "Retrying request to /chat/completions in 0.147000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.6723885868056827 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197617, Requested 3121. Please try again in 221ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.6723885868056827 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197617, Requested 3121. Please try again in 221ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.9258378308185935 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.9258378308185935 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7142263053371477 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197579, Requested 3125. Please try again in 211ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7142263053371477 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197579, Requested 3125. Please try again in 211ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7118103939185478 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197539, Requested 3183. Please try again in 216ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7118103939185478 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197539, Requested 3183. Please try again in 216ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.218000 seconds\n",
      "Retrying request to /chat/completions in 0.218000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.8913751834226149 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197475, Requested 3190. Please try again in 199ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.8913751834226149 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197475, Requested 3190. Please try again in 199ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 14, 7, 9, 1, 3, 5, 6, 11, 13, 10, 15, 21, 22, 27, 17, 19, 26, 16, 20, 25, 12, 28, 2, 4, 8, 23, 24, 18, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.039000 seconds\n",
      "Retrying request to /chat/completions in 0.039000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.027000 seconds\n",
      "Retrying request to /chat/completions in 0.027000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[200]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197338, Requested 3189. Please try again in 158ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[200]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197338, Requested 3189. Please try again in 158ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  73%|███████▎  | 161/220 [01:05<00:36,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[132]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[132]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.138000 seconds\n",
      "Retrying request to /chat/completions in 0.138000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.35639875635961005 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.35639875635961005 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.057000 seconds\n",
      "Retrying request to /chat/completions in 0.057000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.5916865019780602 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197490, Requested 3186. Please try again in 202ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.5916865019780602 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197490, Requested 3186. Please try again in 202ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.8246788274440986 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.8246788274440986 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.3723500579814035 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197756, Requested 3052. Please try again in 242ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.3723500579814035 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197756, Requested 3052. Please try again in 242ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.246000 seconds\n",
      "Retrying request to /chat/completions in 0.246000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.239000 seconds\n",
      "Retrying request to /chat/completions in 0.239000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.187000 seconds\n",
      "Retrying request to /chat/completions in 0.187000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  74%|███████▍  | 163/220 [01:05<00:27,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[100]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199578, Requested 3073. Please try again in 795ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[100]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199578, Requested 3073. Please try again in 795ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.793000 seconds\n",
      "Retrying request to /chat/completions in 0.793000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.794000 seconds\n",
      "Retrying request to /chat/completions in 0.794000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.750000 seconds\n",
      "Retrying request to /chat/completions in 0.750000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.775000 seconds\n",
      "Retrying request to /chat/completions in 0.775000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.622000 seconds\n",
      "Retrying request to /chat/completions in 0.622000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.647000 seconds\n",
      "Retrying request to /chat/completions in 0.647000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.645000 seconds\n",
      "Retrying request to /chat/completions in 0.645000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.547000 seconds\n",
      "Retrying request to /chat/completions in 0.547000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.539000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.539000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.531000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.531000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.430000 seconds\n",
      "Retrying request to /chat/completions in 0.430000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.048000 seconds\n",
      "Retrying request to /chat/completions in 0.048000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.067000 seconds\n",
      "Retrying request to /chat/completions in 0.067000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.062000 seconds\n",
      "Retrying request to /chat/completions in 0.062000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.046000 seconds\n",
      "Retrying request to /chat/completions in 0.046000 seconds\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 1.7282943951608607 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 1.7282943951608607 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.31399934856381806 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196972, Requested 3143. Please try again in 34ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.31399934856381806 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196972, Requested 3143. Please try again in 34ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.033000 seconds\n",
      "Retrying request to /chat/completions in 0.033000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.045000 seconds\n",
      "Retrying request to /chat/completions in 0.045000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.035000 seconds\n",
      "Retrying request to /chat/completions in 0.035000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.026000 seconds\n",
      "Retrying request to /chat/completions in 0.026000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  75%|███████▌  | 165/220 [01:06<00:27,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.768000 seconds\n",
      "Retrying request to /chat/completions in 0.768000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.772000 seconds\n",
      "Retrying request to /chat/completions in 0.772000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[201]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199436, Requested 3183. Please try again in 785ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[201]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199436, Requested 3183. Please try again in 785ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.781000 seconds\n",
      "Retrying request to /chat/completions in 0.781000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.771000 seconds\n",
      "Retrying request to /chat/completions in 0.771000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.771000 seconds\n",
      "Retrying request to /chat/completions in 0.771000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.745000 seconds\n",
      "Retrying request to /chat/completions in 0.745000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[66]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 198732, Requested 3121. Please try again in 555ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[66]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 198732, Requested 3121. Please try again in 555ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  76%|███████▌  | 167/220 [01:07<00:19,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Reranking, new rank list for nodes: [0, 7, 11, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 10, 9, 8, 6, 5, 4, 3, 2, 1]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.443000 seconds\n",
      "Retrying request to /chat/completions in 0.443000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[167]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 198183, Requested 3190. Please try again in 411ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[167]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 198183, Requested 3190. Please try again in 411ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  76%|███████▋  | 168/220 [01:07<00:17,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.270000 seconds\n",
      "Retrying request to /chat/completions in 0.270000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.150000 seconds\n",
      "Retrying request to /chat/completions in 0.150000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.185000 seconds\n",
      "Retrying request to /chat/completions in 0.185000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[32]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197540, Requested 3094. Please try again in 190ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[32]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197540, Requested 3094. Please try again in 190ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  77%|███████▋  | 169/220 [01:07<00:18,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.4676361918643094 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197588, Requested 3133. Please try again in 216ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.4676361918643094 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197588, Requested 3133. Please try again in 216ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.3468174220459692 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197465, Requested 3125. Please try again in 177ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.3468174220459692 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197465, Requested 3125. Please try again in 177ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.103000 seconds\n",
      "Retrying request to /chat/completions in 0.103000 seconds\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.23639778674076195 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.23639778674076195 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.3396164026100308 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.3396164026100308 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.6404390295469762 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.6404390295469762 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.124000 seconds\n",
      "Retrying request to /chat/completions in 0.124000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.165000 seconds\n",
      "Retrying request to /chat/completions in 0.165000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.033000 seconds\n",
      "Retrying request to /chat/completions in 0.033000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.4199307505039164 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199751, Requested 3001. Please try again in 825ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.4199307505039164 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199751, Requested 3001. Please try again in 825ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.834000 seconds\n",
      "Retrying request to /chat/completions in 0.834000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.818000 seconds\n",
      "Retrying request to /chat/completions in 0.818000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  77%|███████▋  | 170/220 [01:08<00:18,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7565910512094725 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199328, Requested 3191. Please try again in 755ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7565910512094725 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199328, Requested 3191. Please try again in 755ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.8039683124504002 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.8039683124504002 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.570000 seconds\n",
      "Retrying request to /chat/completions in 0.570000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.574000 seconds\n",
      "Retrying request to /chat/completions in 0.574000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450000 seconds\n",
      "Retrying request to /chat/completions in 0.450000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.344000 seconds\n",
      "Retrying request to /chat/completions in 0.344000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.250000 seconds\n",
      "Retrying request to /chat/completions in 0.250000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.264000 seconds\n",
      "Retrying request to /chat/completions in 0.264000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.200000 seconds\n",
      "Retrying request to /chat/completions in 0.200000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.025000 seconds\n",
      "Retrying request to /chat/completions in 0.025000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.38198611214830247 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199664, Requested 2908. Please try again in 771ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.38198611214830247 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199664, Requested 2908. Please try again in 771ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7598439037568222 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7598439037568222 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.781000 seconds\n",
      "Retrying request to /chat/completions in 0.781000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.784000 seconds\n",
      "Retrying request to /chat/completions in 0.784000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.773000 seconds\n",
      "Retrying request to /chat/completions in 0.773000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.787000 seconds\n",
      "Retrying request to /chat/completions in 0.787000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.750000 seconds\n",
      "Retrying request to /chat/completions in 0.750000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.753000 seconds\n",
      "Retrying request to /chat/completions in 0.753000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.700000 seconds\n",
      "Retrying request to /chat/completions in 0.700000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.514000 seconds\n",
      "Retrying request to /chat/completions in 0.514000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.547000 seconds\n",
      "Retrying request to /chat/completions in 0.547000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.546000 seconds\n",
      "Retrying request to /chat/completions in 0.546000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.433000 seconds\n",
      "Retrying request to /chat/completions in 0.433000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.4549888768651773 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 198463, Requested 3001. Please try again in 439ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.4549888768651773 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 198463, Requested 3001. Please try again in 439ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.470000 seconds\n",
      "Retrying request to /chat/completions in 0.470000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.12431336581162244 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.12431336581162244 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.31988000486307433 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.31988000486307433 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.2881052537958976 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 198293, Requested 3120. Please try again in 423ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.2881052537958976 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 198293, Requested 3120. Please try again in 423ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[168]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 198189, Requested 3213. Please try again in 420ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[168]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 198189, Requested 3213. Please try again in 420ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.427000 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  78%|███████▊  | 171/220 [01:09<00:36,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying request to /chat/completions in 0.427000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.07361725399411956 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.07361725399411956 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "ERROR:ragas.executor:Exception raised in Job[202]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 198210, Requested 3186. Please try again in 418ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[202]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 198210, Requested 3186. Please try again in 418ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.256000 seconds\n",
      "Retrying request to /chat/completions in 0.256000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.245000 seconds\n",
      "Retrying request to /chat/completions in 0.245000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[134]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[134]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  79%|███████▊  | 173/220 [01:10<00:21,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.135000 seconds\n",
      "Retrying request to /chat/completions in 0.135000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.925000 seconds\n",
      "Retrying request to /chat/completions in 0.925000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.920000 seconds\n",
      "Retrying request to /chat/completions in 0.920000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  79%|███████▉  | 174/220 [01:10<00:19,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.721000 seconds\n",
      "Retrying request to /chat/completions in 0.721000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.747000 seconds\n",
      "Retrying request to /chat/completions in 0.747000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[67]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[67]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.789000 seconds\n",
      "Retrying request to /chat/completions in 0.789000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.746000 seconds\n",
      "Retrying request to /chat/completions in 0.746000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.609000 seconds\n",
      "Retrying request to /chat/completions in 0.609000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.534000 seconds\n",
      "Retrying request to /chat/completions in 0.534000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[34]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 198121, Requested 3133. Please try again in 376ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[34]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 198121, Requested 3133. Please try again in 376ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  80%|████████  | 176/220 [01:10<00:15,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7462919873760323 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197906, Requested 3156. Please try again in 318ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7462919873760323 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197906, Requested 3156. Please try again in 318ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 2, 4, 3, 5, 6, 7, 8, 10, 9, 11, 13, 14, 15, 12, 16, 17, 18, 19, 20, 21, 27, 29, 25, 26, 22, 23, 24, 28]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.184000 seconds\n",
      "Retrying request to /chat/completions in 0.184000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.071000 seconds\n",
      "Retrying request to /chat/completions in 0.071000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.003000 seconds\n",
      "Retrying request to /chat/completions in 0.003000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 1.8228058844566606 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199510, Requested 2908. Please try again in 725ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 1.8228058844566606 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199510, Requested 2908. Please try again in 725ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.764000 seconds\n",
      "Retrying request to /chat/completions in 0.764000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7926295644822948 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199278, Requested 3104. Please try again in 714ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7926295644822948 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199278, Requested 3104. Please try again in 714ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.718000 seconds\n",
      "Retrying request to /chat/completions in 0.718000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 1.0148754067213541 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199233, Requested 3191. Please try again in 727ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 1.0148754067213541 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199233, Requested 3191. Please try again in 727ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.750000 seconds\n",
      "Retrying request to /chat/completions in 0.750000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.671000 seconds\n",
      "Retrying request to /chat/completions in 0.671000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.685000 seconds\n",
      "Retrying request to /chat/completions in 0.685000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487000 seconds\n",
      "Retrying request to /chat/completions in 0.487000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.482000 seconds\n",
      "Retrying request to /chat/completions in 0.482000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.9189347958296615 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 198248, Requested 3165. Please try again in 423ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.9189347958296615 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 198248, Requested 3165. Please try again in 423ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.6304542427062353 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.6304542427062353 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.261000 seconds\n",
      "Retrying request to /chat/completions in 0.261000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 5, 7, 1, 10, 4, 17, 16, 22, 14, 24, 25, 13, 27, 28, 29, 11, 15, 18, 23, 9, 12, 2, 3, 21, 26, 8, 6, 19, 20]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[102]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197063, Requested 3001. Please try again in 19ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[102]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197063, Requested 3001. Please try again in 19ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  80%|████████  | 177/220 [01:12<00:23,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7002663540847408 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196969, Requested 3112. Please try again in 24ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7002663540847408 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196969, Requested 3112. Please try again in 24ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.020000 seconds\n",
      "Retrying request to /chat/completions in 0.020000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.028000 seconds\n",
      "Retrying request to /chat/completions in 0.028000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.025000 seconds\n",
      "Retrying request to /chat/completions in 0.025000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.015000 seconds\n",
      "Retrying request to /chat/completions in 0.015000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 1.7405023396099404 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 1.7405023396099404 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.821000 seconds\n",
      "Retrying request to /chat/completions in 0.821000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.818000 seconds\n",
      "Retrying request to /chat/completions in 0.818000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.4944972517131957 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199519, Requested 3199. Please try again in 815ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.4944972517131957 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199519, Requested 3199. Please try again in 815ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[135]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[135]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  81%|████████  | 178/220 [01:12<00:20,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.13315998066923673 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.13315998066923673 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.598000 seconds\n",
      "Retrying request to /chat/completions in 0.598000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.620000 seconds\n",
      "Retrying request to /chat/completions in 0.620000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.9898526035344742 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199269, Requested 3246. Please try again in 754ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.9898526035344742 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199269, Requested 3246. Please try again in 754ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  81%|████████▏ | 179/220 [01:12<00:16,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.576000 seconds\n",
      "Retrying request to /chat/completions in 0.576000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.564000 seconds\n",
      "Retrying request to /chat/completions in 0.564000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.477000 seconds\n",
      "Retrying request to /chat/completions in 0.477000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489000 seconds\n",
      "Retrying request to /chat/completions in 0.489000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.648000 seconds\n",
      "Retrying request to /chat/completions in 0.648000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.427000 seconds\n",
      "Retrying request to /chat/completions in 0.427000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "ERROR:ragas.executor:Exception raised in Job[136]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[136]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  82%|████████▏ | 180/220 [01:13<00:18,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.453000 seconds\n",
      "Retrying request to /chat/completions in 0.453000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.445000 seconds\n",
      "Retrying request to /chat/completions in 0.445000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.369000 seconds\n",
      "Retrying request to /chat/completions in 0.369000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.303000 seconds\n",
      "Retrying request to /chat/completions in 0.303000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.04585900133916421 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 198084, Requested 3104. Please try again in 356ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.04585900133916421 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 198084, Requested 3104. Please try again in 356ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.257000 seconds\n",
      "Retrying request to /chat/completions in 0.257000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.223000 seconds\n",
      "Retrying request to /chat/completions in 0.223000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[203]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197541, Requested 3191. Please try again in 219ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[203]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197541, Requested 3191. Please try again in 219ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  82%|████████▏ | 181/220 [01:13<00:17,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.070000 seconds\n",
      "Retrying request to /chat/completions in 0.070000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.139000 seconds\n",
      "Retrying request to /chat/completions in 0.139000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.079000 seconds\n",
      "Retrying request to /chat/completions in 0.079000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 1.1943534665702367 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196925, Requested 3124. Please try again in 14ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 1.1943534665702367 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196925, Requested 3124. Please try again in 14ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.4233675844933942 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.4233675844933942 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.31777725472640106 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199410, Requested 3126. Please try again in 760ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.31777725472640106 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199410, Requested 3126. Please try again in 760ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.758000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.758000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.751000 seconds\n",
      "Retrying request to /chat/completions in 0.751000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.730000 seconds\n",
      "Retrying request to /chat/completions in 0.730000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.745000 seconds\n",
      "Retrying request to /chat/completions in 0.745000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  83%|████████▎ | 182/220 [01:14<00:16,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.621000 seconds\n",
      "Retrying request to /chat/completions in 0.621000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.555000 seconds\n",
      "Retrying request to /chat/completions in 0.555000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.478000 seconds\n",
      "Retrying request to /chat/completions in 0.478000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.41257838567249894 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.41257838567249894 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.158000 seconds\n",
      "Retrying request to /chat/completions in 0.158000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.2131814251945614 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197550, Requested 3034. Please try again in 175ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.2131814251945614 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197550, Requested 3034. Please try again in 175ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.192000 seconds\n",
      "Retrying request to /chat/completions in 0.192000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.169000 seconds\n",
      "Retrying request to /chat/completions in 0.169000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.735000 seconds\n",
      "Retrying request to /chat/completions in 0.735000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.772000 seconds\n",
      "Retrying request to /chat/completions in 0.772000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[35]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199479, Requested 3104. Please try again in 774ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[35]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199479, Requested 3104. Please try again in 774ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  83%|████████▎ | 183/220 [01:14<00:19,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.772000 seconds\n",
      "Retrying request to /chat/completions in 0.772000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.769000 seconds\n",
      "Retrying request to /chat/completions in 0.769000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.695000 seconds\n",
      "Retrying request to /chat/completions in 0.695000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.711000 seconds\n",
      "Retrying request to /chat/completions in 0.711000 seconds\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.23534350826211337 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.23534350826211337 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.714000 seconds\n",
      "Retrying request to /chat/completions in 0.714000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.3140922183877346 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.3140922183877346 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.568000 seconds\n",
      "Retrying request to /chat/completions in 0.568000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.401000 seconds\n",
      "Retrying request to /chat/completions in 0.401000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.366000 seconds\n",
      "Retrying request to /chat/completions in 0.366000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.352000 seconds\n",
      "Retrying request to /chat/completions in 0.352000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.200000 seconds\n",
      "Retrying request to /chat/completions in 0.200000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 3, 8, 5, 6, 2, 10, 20, 17, 24, 27, 19, 9, 26, 22, 21, 14, 18, 7, 1, 11, 12, 16, 4, 25, 23, 15, 13, 28, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.727000 seconds\n",
      "Retrying request to /chat/completions in 0.727000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.732000 seconds\n",
      "Retrying request to /chat/completions in 0.732000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.733000 seconds\n",
      "Retrying request to /chat/completions in 0.733000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.716000 seconds\n",
      "Retrying request to /chat/completions in 0.716000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.16845093211768092 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199276, Requested 3141. Please try again in 725ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.16845093211768092 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199276, Requested 3141. Please try again in 725ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.734000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.734000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.12545099986412 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199167, Requested 3246. Please try again in 723ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.12545099986412 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199167, Requested 3246. Please try again in 723ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.740000 seconds\n",
      "Retrying request to /chat/completions in 0.740000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.574000 seconds\n",
      "Retrying request to /chat/completions in 0.574000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497000 seconds\n",
      "Retrying request to /chat/completions in 0.497000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.488000 seconds\n",
      "Retrying request to /chat/completions in 0.488000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[170]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[170]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  84%|████████▎ | 184/220 [01:15<00:25,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.375000 seconds\n",
      "Retrying request to /chat/completions in 0.375000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.15946818255390227 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197155, Requested 3053. Please try again in 62ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.15946818255390227 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197155, Requested 3053. Please try again in 62ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.060000 seconds\n",
      "Retrying request to /chat/completions in 0.060000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.063000 seconds\n",
      "Retrying request to /chat/completions in 0.063000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.091000 seconds\n",
      "Retrying request to /chat/completions in 0.091000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[69]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[69]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.040084284670758974 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197077, Requested 3126. Please try again in 60ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.040084284670758974 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197077, Requested 3126. Please try again in 60ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  84%|████████▍ | 185/220 [01:16<00:23,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.054000 seconds\n",
      "Retrying request to /chat/completions in 0.054000 seconds\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.8168981948429692 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197025, Requested 3184. Please try again in 62ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.8168981948429692 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197025, Requested 3184. Please try again in 62ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.036000 seconds\n",
      "Retrying request to /chat/completions in 0.036000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[204]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[204]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.11994724083433783 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199726, Requested 3034. Please try again in 828ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.11994724083433783 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199726, Requested 3034. Please try again in 828ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.830000 seconds\n",
      "Retrying request to /chat/completions in 0.830000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[103]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199681, Requested 3112. Please try again in 837ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[103]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199681, Requested 3112. Please try again in 837ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  85%|████████▌ | 187/220 [01:16<00:13,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.817000 seconds\n",
      "Retrying request to /chat/completions in 0.817000 seconds\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.3105685410698309 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199588, Requested 3141. Please try again in 818ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.3105685410698309 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199588, Requested 3141. Please try again in 818ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.861000 seconds\n",
      "Retrying request to /chat/completions in 0.861000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[137]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199545, Requested 3199. Please try again in 823ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[137]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199545, Requested 3199. Please try again in 823ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.822000 seconds\n",
      "Retrying request to /chat/completions in 0.822000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [1, 2, 9, 11, 13, 25, 0, 4, 7, 10, 12, 14, 16, 18, 19, 24, 21, 22, 27, 28, 3, 5, 6, 8, 17, 20, 23, 26, 15, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489000 seconds\n",
      "Retrying request to /chat/completions in 0.489000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.414000 seconds\n",
      "Retrying request to /chat/completions in 0.414000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.475000 seconds\n",
      "Retrying request to /chat/completions in 0.475000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395000 seconds\n",
      "Retrying request to /chat/completions in 0.395000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.328000 seconds\n",
      "Retrying request to /chat/completions in 0.328000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.208000 seconds\n",
      "Retrying request to /chat/completions in 0.208000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.149000 seconds\n",
      "Retrying request to /chat/completions in 0.149000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.060000 seconds\n",
      "Retrying request to /chat/completions in 0.060000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.035000 seconds\n",
      "Retrying request to /chat/completions in 0.035000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.8987683803555139 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199884, Requested 3256. Please try again in 941ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.8987683803555139 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199884, Requested 3256. Please try again in 941ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[171]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199766, Requested 3246. Please try again in 903ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[171]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199766, Requested 3246. Please try again in 903ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  86%|████████▋ | 190/220 [01:17<00:11,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.20868856436592376 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.20868856436592376 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.821000 seconds\n",
      "Retrying request to /chat/completions in 0.821000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.840000 seconds\n",
      "Retrying request to /chat/completions in 0.840000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.824000 seconds\n",
      "Retrying request to /chat/completions in 0.824000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.700000 seconds\n",
      "Retrying request to /chat/completions in 0.700000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.691000 seconds\n",
      "Retrying request to /chat/completions in 0.691000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[104]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 198940, Requested 3034. Please try again in 592ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[104]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 198940, Requested 3034. Please try again in 592ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  87%|████████▋ | 191/220 [01:17<00:10,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 2, 3, 4, 24, 11, 13, 27, 21, 25, 26, 15, 16, 17, 20, 19, 14, 23, 18, 6, 7, 10, 5, 9, 12, 8, 28, 29, 22]HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.551000 seconds\n",
      "Retrying request to /chat/completions in 0.551000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.3356640911019976 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.3356640911019976 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.385000 seconds\n",
      "Retrying request to /chat/completions in 0.385000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402000 seconds\n",
      "Retrying request to /chat/completions in 0.402000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 1.3401800904654402 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197701, Requested 3184. Please try again in 265ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 1.3401800904654402 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197701, Requested 3184. Please try again in 265ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.111000 seconds\n",
      "Retrying request to /chat/completions in 0.111000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.127000 seconds\n",
      "Retrying request to /chat/completions in 0.127000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.4238683720853812 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197193, Requested 2941. Please try again in 40ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.4238683720853812 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197193, Requested 2941. Please try again in 40ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.199000 seconds\n",
      "Retrying request to /chat/completions in 0.199000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.9675335202158053 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197387, Requested 3197. Please try again in 175ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.9675335202158053 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197387, Requested 3197. Please try again in 175ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[205]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[205]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  88%|████████▊ | 193/220 [01:18<00:09,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.102000 seconds\n",
      "Retrying request to /chat/completions in 0.102000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.8445057816120256 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197186, Requested 3131. Please try again in 95ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.8445057816120256 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197186, Requested 3131. Please try again in 95ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.3746448714942776 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197173, Requested 3163. Please try again in 100ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.3746448714942776 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197173, Requested 3163. Please try again in 100ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.038000 seconds\n",
      "Retrying request to /chat/completions in 0.038000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.094000 seconds\n",
      "Retrying request to /chat/completions in 0.094000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.856000 seconds\n",
      "Retrying request to /chat/completions in 0.856000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.811000 seconds\n",
      "Retrying request to /chat/completions in 0.811000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[36]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199541, Requested 3141. Please try again in 804ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[36]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199541, Requested 3141. Please try again in 804ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  88%|████████▊ | 194/220 [01:18<00:08,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.749000 seconds\n",
      "Retrying request to /chat/completions in 0.749000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.1730782279464359 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199359, Requested 3208. Please try again in 770ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.1730782279464359 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199359, Requested 3208. Please try again in 770ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[70]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[70]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  89%|████████▊ | 195/220 [01:19<00:07,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.769000 seconds\n",
      "Retrying request to /chat/completions in 0.769000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.17851056093493045 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199318, Requested 3065. Please try again in 714ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.17851056093493045 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199318, Requested 3065. Please try again in 714ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.669000 seconds\n",
      "Retrying request to /chat/completions in 0.669000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.639000 seconds\n",
      "Retrying request to /chat/completions in 0.639000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.619000 seconds\n",
      "Retrying request to /chat/completions in 0.619000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.2829688074197574 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 198419, Requested 3256. Please try again in 502ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.2829688074197574 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 198419, Requested 3256. Please try again in 502ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.400000 seconds\n",
      "Retrying request to /chat/completions in 0.400000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  89%|████████▉ | 196/220 [01:19<00:09,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.2259403918403995 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196841, Requested 3177. Please try again in 5ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.2259403918403995 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196841, Requested 3177. Please try again in 5ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.943000 seconds\n",
      "Retrying request to /chat/completions in 0.943000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.960000 seconds\n",
      "Retrying request to /chat/completions in 0.960000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.921000 seconds\n",
      "Retrying request to /chat/completions in 0.921000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.841000 seconds\n",
      "Retrying request to /chat/completions in 0.841000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.758000 seconds\n",
      "Retrying request to /chat/completions in 0.758000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.788000 seconds\n",
      "Retrying request to /chat/completions in 0.788000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.792000 seconds\n",
      "Retrying request to /chat/completions in 0.792000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.709000 seconds\n",
      "Retrying request to /chat/completions in 0.709000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.746000 seconds\n",
      "Retrying request to /chat/completions in 0.746000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.788000 seconds\n",
      "Retrying request to /chat/completions in 0.788000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7894470901000056 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199061, Requested 3131. Please try again in 657ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7894470901000056 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199061, Requested 3131. Please try again in 657ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.573000 seconds\n",
      "Retrying request to /chat/completions in 0.573000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 1.7179275235254179 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197918, Requested 3163. Please try again in 324ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 1.7179275235254179 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197918, Requested 3163. Please try again in 324ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.759000 seconds\n",
      "Retrying request to /chat/completions in 0.759000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.742000 seconds\n",
      "Retrying request to /chat/completions in 0.742000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.738000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.750000 seconds\n",
      "Retrying request to /chat/completions in 0.738000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "Retrying request to /chat/completions in 0.750000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.762000 seconds\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.762000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.762000 seconds\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "Retrying request to /chat/completions in 0.762000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.550000 seconds\n",
      "Retrying request to /chat/completions in 0.550000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.507000 seconds\n",
      "Retrying request to /chat/completions in 0.507000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.483000 seconds\n",
      "Retrying request to /chat/completions in 0.483000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.48334801107656844 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 198402, Requested 3158. Please try again in 468ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.48334801107656844 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 198402, Requested 3158. Please try again in 468ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.477000 seconds\n",
      "Retrying request to /chat/completions in 0.477000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [2, 1, 3, 7, 0, 4, 5, 6, 8, 9, 10, 12, 13, 14, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 11, 15, 21, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7952266355865811 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199732, Requested 2941. Please try again in 801ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7952266355865811 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199732, Requested 2941. Please try again in 801ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.801000 seconds\n",
      "Retrying request to /chat/completions in 0.801000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[138]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199487, Requested 3184. Please try again in 801ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[138]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199487, Requested 3184. Please try again in 801ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  90%|████████▉ | 197/220 [01:21<00:18,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.08431359617671452 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199472, Requested 3197. Please try again in 800ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.08431359617671452 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199472, Requested 3197. Please try again in 800ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[71]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199405, Requested 3065. Please try again in 741ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[71]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199405, Requested 3065. Please try again in 741ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.762000 seconds\n",
      "Retrying request to /chat/completions in 0.762000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[172]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[172]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.723000 seconds\n",
      "Retrying request to /chat/completions in 0.723000 seconds\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 1.4434648435647577 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 1.4434648435647577 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.830000 seconds\n",
      "Retrying request to /chat/completions in 0.830000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.778000 seconds\n",
      "Retrying request to /chat/completions in 0.778000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7096987974709983 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7096987974709983 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 1.5185786643790755 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199105, Requested 3131. Please try again in 670ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 1.5185786643790755 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199105, Requested 3131. Please try again in 670ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.457000 seconds\n",
      "Retrying request to /chat/completions in 0.457000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  91%|█████████ | 200/220 [01:22<00:09,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.033000 seconds\n",
      "Retrying request to /chat/completions in 0.033000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.058000 seconds\n",
      "Retrying request to /chat/completions in 0.058000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.3836955560839814 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197032, Requested 3052. Please try again in 25ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.3836955560839814 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197032, Requested 3052. Please try again in 25ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.031000 seconds\n",
      "Retrying request to /chat/completions in 0.031000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.026000 seconds\n",
      "Retrying request to /chat/completions in 0.026000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 2, 3, 4, 5, 6, 10, 11, 18, 19, 26, 27, 9, 12, 13, 14, 17, 20, 21, 25, 7, 8, 16, 22, 23, 24, 15, 28, 29]INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.749000 seconds\n",
      "Retrying request to /chat/completions in 0.749000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.725000 seconds\n",
      "Retrying request to /chat/completions in 0.725000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.5024576496830107 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199248, Requested 3131. Please try again in 713ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.5024576496830107 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199248, Requested 3131. Please try again in 713ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.683000 seconds\n",
      "Retrying request to /chat/completions in 0.683000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.696000 seconds\n",
      "Retrying request to /chat/completions in 0.696000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.483000 seconds\n",
      "Retrying request to /chat/completions in 0.483000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.012563030359526328 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 198470, Requested 3158. Please try again in 488ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.012563030359526328 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 198470, Requested 3158. Please try again in 488ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.465000 seconds\n",
      "Retrying request to /chat/completions in 0.465000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.334000 seconds\n",
      "Retrying request to /chat/completions in 0.334000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.295000 seconds\n",
      "Retrying request to /chat/completions in 0.295000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.281000 seconds\n",
      "Retrying request to /chat/completions in 0.281000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.206000 seconds\n",
      "Retrying request to /chat/completions in 0.206000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.180000 seconds\n",
      "Retrying request to /chat/completions in 0.180000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 14, 19, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.019000 seconds\n",
      "Retrying request to /chat/completions in 0.019000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[3]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[3]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.916000 seconds\n",
      "Retrying request to /chat/completions in 0.916000 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  91%|█████████▏| 201/220 [01:23<00:12,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.873000 seconds\n",
      "Retrying request to /chat/completions in 0.873000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.864000 seconds\n",
      "Retrying request to /chat/completions in 0.864000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.861000 seconds\n",
      "Retrying request to /chat/completions in 0.861000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.872000 seconds\n",
      "Retrying request to /chat/completions in 0.872000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[139]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199708, Requested 3177. Please try again in 865ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[139]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199708, Requested 3177. Please try again in 865ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[37]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199555, Requested 3163. Please try again in 815ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[37]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199555, Requested 3163. Please try again in 815ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  92%|█████████▏| 203/220 [01:23<00:07,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.720000 seconds\n",
      "Retrying request to /chat/completions in 0.720000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.837000 seconds\n",
      "Retrying request to /chat/completions in 0.837000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.840000 seconds\n",
      "Retrying request to /chat/completions in 0.840000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[105]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[105]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  93%|█████████▎| 204/220 [01:23<00:06,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.782000 seconds\n",
      "Retrying request to /chat/completions in 0.782000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.6714763250089308 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199462, Requested 3244. Please try again in 811ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.6714763250089308 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199462, Requested 3244. Please try again in 811ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  93%|█████████▎| 205/220 [01:24<00:06,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.279000 seconds\n",
      "Retrying request to /chat/completions in 0.279000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  94%|█████████▎| 206/220 [01:24<00:05,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.250000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.246000 seconds\n",
      "Retrying request to /chat/completions in 0.250000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.234000 seconds\n",
      "Retrying request to /chat/completions in 0.246000 seconds\n",
      "Retrying request to /chat/completions in 0.234000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.246000 seconds\n",
      "Retrying request to /chat/completions in 0.246000 seconds\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7771740341948125 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197653, Requested 3137. Please try again in 237ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.7771740341948125 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197653, Requested 3137. Please try again in 237ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.203000 seconds\n",
      "Retrying request to /chat/completions in 0.203000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.254000 seconds\n",
      "Retrying request to /chat/completions in 0.254000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.255000 seconds\n",
      "Retrying request to /chat/completions in 0.255000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.174000 seconds\n",
      "Retrying request to /chat/completions in 0.174000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.095000 seconds\n",
      "Retrying request to /chat/completions in 0.095000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[106]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197031, Requested 3158. Please try again in 56ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[106]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197031, Requested 3158. Please try again in 56ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  94%|█████████▍| 207/220 [01:24<00:04,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.043000 seconds\n",
      "Retrying request to /chat/completions in 0.043000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[173]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196981, Requested 3208. Please try again in 56ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[173]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196981, Requested 3208. Please try again in 56ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.768000 seconds\n",
      "Retrying request to /chat/completions in 0.768000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.778000 seconds\n",
      "Retrying request to /chat/completions in 0.778000 seconds\n",
      "ERROR:ragas.executor:Exception raised in Job[206]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199459, Requested 3131. Please try again in 777ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[206]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199459, Requested 3131. Please try again in 777ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  95%|█████████▌| 209/220 [01:25<00:02,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.24217007729282414 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199438, Requested 3052. Please try again in 747ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.24217007729282414 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199438, Requested 3052. Please try again in 747ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[207]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199420, Requested 3131. Please try again in 765ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[207]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199420, Requested 3131. Please try again in 765ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.3318862826950868 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.3318862826950868 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.775000 seconds\n",
      "Retrying request to /chat/completions in 0.775000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.709000 seconds\n",
      "Retrying request to /chat/completions in 0.709000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.756000 seconds\n",
      "Retrying request to /chat/completions in 0.756000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.18615214195650376 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.18615214195650376 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.341000 seconds\n",
      "Retrying request to /chat/completions in 0.341000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.371000 seconds\n",
      "Retrying request to /chat/completions in 0.371000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.275000 seconds\n",
      "Retrying request to /chat/completions in 0.275000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.193000 seconds\n",
      "Retrying request to /chat/completions in 0.193000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.801000 seconds\n",
      "Retrying request to /chat/completions in 0.801000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.800000 seconds\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "Retrying request to /chat/completions in 0.800000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.774000 seconds\n",
      "Retrying request to /chat/completions in 0.774000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.120000 seconds\n",
      "Retrying request to /chat/completions in 0.120000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.806000 seconds\n",
      "Retrying request to /chat/completions in 0.806000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.796000 seconds\n",
      "Retrying request to /chat/completions in 0.796000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.803000 seconds\n",
      "Retrying request to /chat/completions in 0.803000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.554000 seconds\n",
      "Retrying request to /chat/completions in 0.554000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.552000 seconds\n",
      "Retrying request to /chat/completions in 0.552000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 2, 1, 3, 4, 11, 24, 23, 25, 18, 14, 9, 16, 17, 19, 13, 21, 27, 10, 7, 6, 5, 20, 29, 22, 8, 12, 15, 26, 28]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.05510806713161176 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197029, Requested 3047. Please try again in 22ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.05510806713161176 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197029, Requested 3047. Please try again in 22ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.16990539239584734 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196995, Requested 3064. Please try again in 17ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.16990539239584734 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196995, Requested 3064. Please try again in 17ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.725551771344594 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196929, Requested 3150. Please try again in 23ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.725551771344594 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196929, Requested 3150. Please try again in 23ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.9134906403745153 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196923, Requested 3131. Please try again in 16ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.9134906403745153 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196923, Requested 3131. Please try again in 16ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 1.2570719783041235 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196912, Requested 3137. Please try again in 14ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 1.2570719783041235 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196912, Requested 3137. Please try again in 14ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.9254601360480799 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196902, Requested 3204. Please try again in 31ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.9254601360480799 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 196902, Requested 3204. Please try again in 31ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.011000 seconds\n",
      "Retrying request to /chat/completions in 0.011000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 1.5374149495548055 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Request too large for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Requested 3244. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 1.5374149495548055 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Request too large for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Requested 3244. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.6208199515732566 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199415, Requested 3194. Please try again in 782ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.6208199515732566 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199415, Requested 3194. Please try again in 782ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.617000 seconds\n",
      "Retrying request to /chat/completions in 0.617000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  96%|█████████▌| 211/220 [01:27<00:04,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.038000 seconds\n",
      "Retrying request to /chat/completions in 0.038000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.825000 seconds\n",
      "Retrying request to /chat/completions in 0.825000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.785000 seconds\n",
      "Retrying request to /chat/completions in 0.785000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 2, 6, 7, 3, 8, 14, 12, 15, 25, 26, 19, 9, 16, 17, 29, 11, 21, 24, 23, 22, 18, 28, 20, 10, 5, 4, 1, 13, 27]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.689000 seconds\n",
      "Retrying request to /chat/completions in 0.689000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.677000 seconds\n",
      "Retrying request to /chat/completions in 0.677000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.557000 seconds\n",
      "Retrying request to /chat/completions in 0.557000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.291000 seconds\n",
      "Retrying request to /chat/completions in 0.291000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  96%|█████████▋| 212/220 [01:28<00:05,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.908000 seconds\n",
      "Retrying request to /chat/completions in 0.908000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.813000 seconds\n",
      "Retrying request to /chat/completions in 0.813000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.811000 seconds\n",
      "Retrying request to /chat/completions in 0.811000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.807000 seconds\n",
      "Retrying request to /chat/completions in 0.807000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.741000 seconds\n",
      "Retrying request to /chat/completions in 0.741000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [1, 3, 0, 5, 2, 10, 11, 9, 8, 17, 19, 21, 20, 22, 23, 28, 18, 16, 7, 13, 12, 14, 26, 27, 6, 4, 15, 24, 25, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  97%|█████████▋| 213/220 [01:29<00:05,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [2, 1, 4, 3, 5, 7, 13, 9, 8, 12, 27, 15, 14, 0, 25, 19, 18, 26, 20, 23, 24, 28, 29, 22, 17, 6, 10, 16, 11, 21]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[107]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199751, Requested 3150. Please try again in 870ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[107]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 199751, Requested 3150. Please try again in 870ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  97%|█████████▋| 214/220 [01:29<00:03,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.111000 seconds\n",
      "Retrying request to /chat/completions in 0.111000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.873000 seconds\n",
      "Retrying request to /chat/completions in 0.873000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.869000 seconds\n",
      "Retrying request to /chat/completions in 0.869000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.839000 seconds\n",
      "Retrying request to /chat/completions in 0.839000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 4, 14, 3, 6, 7, 16, 11, 12, 13, 17, 21, 22, 27, 24, 28, 9, 19, 15, 20, 25, 26, 1, 10, 5, 8, 2, 18, 23, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  98%|█████████▊| 215/220 [01:30<00:03,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 1.8713123363829791 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197375, Requested 3204. Please try again in 173ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 1.8713123363829791 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197375, Requested 3204. Please try again in 173ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[174]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197341, Requested 3244. Please try again in 175ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[174]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197341, Requested 3244. Please try again in 175ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine:  98%|█████████▊| 216/220 [01:30<00:02,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:ragas.executor:Exception raised in Job[208]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197359, Requested 3137. Please try again in 148ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[208]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-W3GgyascxGPcbC3NSuuLUYGT on tokens per min (TPM): Limit 200000, Used 197359, Requested 3137. Please try again in 148ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 6, 4, 3, 5, 7, 1, 2, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine: 100%|█████████▉| 219/220 [01:32<00:00,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "After Reranking, new rank list for nodes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Query Engine: 100%|██████████| 220/220 [01:35<00:00,  2.31it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'QueryResponse' object has no attribute 'source_nodes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_engine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_engine_with_reranker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluator_llm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mOpenAIEmbedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m df_result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mto_pandas()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#df_result.to_parquet(\"../data/processed_data/df_result_ragas_without_reranking.parquet\")\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/proyectos_propios/jobs/teamstation/.venv/lib/python3.11/site-packages/ragas/integrations/llama_index.py:76\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(query_engine, dataset, metrics, llm, embeddings, raise_exceptions, column_map, run_config)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[1;32m     75\u001b[0m         answers\u001b[38;5;241m.\u001b[39mappend(r\u001b[38;5;241m.\u001b[39mresponse)\n\u001b[0;32m---> 76\u001b[0m         contexts\u001b[38;5;241m.\u001b[39mappend([n\u001b[38;5;241m.\u001b[39mnode\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_nodes\u001b[49m])\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# create HF dataset\u001b[39;00m\n\u001b[1;32m     79\u001b[0m hf_dataset \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mfrom_dict(\n\u001b[1;32m     80\u001b[0m     {\n\u001b[1;32m     81\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: queries,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m     }\n\u001b[1;32m     85\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'QueryResponse' object has no attribute 'source_nodes'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "result = evaluate(\n",
    "    query_engine=query_engine_with_reranker,\n",
    "    metrics=metrics,\n",
    "    dataset=dataset,\n",
    "    llm=evaluator_llm,\n",
    "    embeddings=OpenAIEmbedding(),\n",
    ")\n",
    "\n",
    "df_result = result.to_pandas()\n",
    "#df_result.to_parquet(\"../data/processed_data/df_result_ragas_without_reranking.parquet\")\n",
    "\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresult\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_precision,\n",
    "    context_recall,\n",
    ")\n",
    "#from ragas.metrics.critique import harmfulness\n",
    "\n",
    "metrics = [\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    #context_precision,\n",
    "    #context_recall,\n",
    "    #harmfulness,\n",
    "]\n",
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "# using GPT 3.5, use GPT 4 / 4-turbo for better accuracy\n",
    "evaluator_llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "df = pd.read_parquet(\"../data/processed_data/df_eval.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What are the frequently encountered adverse reactions associated with Keytruda?',\n",
       " 'Which side effects are typically seen in patients receiving Keytruda therapy?']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = df[[\"augmented_questions\"]].rename(columns = {\"augmented_questions\":\"question\"})\n",
    "\n",
    "ds_dict = ds.to_dict()\n",
    "ds_dict[\"question\"] = [v for k, v in ds_dict[\"question\"].items()] \n",
    "ds_dict[\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question'],\n",
       "    num_rows: 2\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ds_dict = ds.to_dict()\n",
    "ds_dict[\"question\"] = [v for k, v in ds_dict[\"question\"].items()] \n",
    "\n",
    "dataset = Dataset.from_dict(ds_dict)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RAGQueryEngine' object has no attribute 'aquery'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_engine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_engine_with_reranker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluator_llm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mOpenAIEmbedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m df_result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mto_pandas()\n\u001b[1;32m     12\u001b[0m df_result\n",
      "File \u001b[0;32m~/Documents/proyectos_propios/jobs/teamstation/.venv/lib/python3.11/site-packages/ragas/integrations/llama_index.py:63\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(query_engine, dataset, metrics, llm, embeddings, raise_exceptions, column_map, run_config)\u001b[0m\n\u001b[1;32m     61\u001b[0m queries \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, q \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(queries):\n\u001b[0;32m---> 63\u001b[0m     exec\u001b[38;5;241m.\u001b[39msubmit(\u001b[43mquery_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maquery\u001b[49m, q, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     65\u001b[0m answers: t\u001b[38;5;241m.\u001b[39mList[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     66\u001b[0m contexts: t\u001b[38;5;241m.\u001b[39mList[t\u001b[38;5;241m.\u001b[39mList[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RAGQueryEngine' object has no attribute 'aquery'"
     ]
    }
   ],
   "source": [
    "\n",
    "result = evaluate(\n",
    "    query_engine=query_engine_with_reranker,\n",
    "    metrics=metrics,\n",
    "    dataset=dataset,\n",
    "    llm=evaluator_llm,\n",
    "    embeddings=OpenAIEmbedding(),\n",
    ")\n",
    "\n",
    "df_result = result.to_pandas()\n",
    "\n",
    "\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>218.000000</td>\n",
       "      <td>220.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.831684</td>\n",
       "      <td>0.859019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.297590</td>\n",
       "      <td>0.301806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.949170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.974852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       faithfulness  answer_relevancy\n",
       "count    218.000000        220.000000\n",
       "mean       0.831684          0.859019\n",
       "std        0.297590          0.301806\n",
       "min        0.000000          0.000000\n",
       "25%        0.666667          0.949170\n",
       "50%        1.000000          0.964384\n",
       "75%        1.000000          0.974852\n",
       "max        1.000000          1.000000"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# without reranking\n",
    "df_result.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>219.000000</td>\n",
       "      <td>220.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.793747</td>\n",
       "      <td>0.890620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.314552</td>\n",
       "      <td>0.259305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.949299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       faithfulness  answer_relevancy\n",
       "count    219.000000        220.000000\n",
       "mean       0.793747          0.890620\n",
       "std        0.314552          0.259305\n",
       "min        0.000000          0.000000\n",
       "25%        0.500000          0.949299\n",
       "50%        1.000000          0.966063\n",
       "75%        1.000000          0.978517\n",
       "max        1.000000          1.000000"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with reranking\n",
    "df_result.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
